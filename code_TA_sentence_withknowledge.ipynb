{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cfe276a1",
   "metadata": {},
   "source": [
    "# Import Libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c088b44f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from transformers import BertTokenizer, TFBertModel\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import os\n",
    "import re\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.metrics import confusion_matrix, classification_report, roc_curve, auc, accuracy_score, precision_score, recall_score, f1_score\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2cfd2a4",
   "metadata": {},
   "source": [
    "# Load Essay Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a23b8d43",
   "metadata": {},
   "outputs": [],
   "source": [
    "stdset = pd.read_csv(\"datasets_ta/esai_siswa.csv\")\n",
    "gpt1set = pd.read_csv(\"datasets_ta/esai_gpt_new.csv\")\n",
    "gpt2set = pd.read_csv(\"datasets_ta/pengetahuan_gpt_new.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52788db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "stdset.info()\n",
    "stdset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b97e9f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt1set.info()\n",
    "gpt1set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88b585f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt2set.info()\n",
    "gpt2set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bfe94ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_sentence(text):\n",
    "    \"\"\"\n",
    "    Text preprocessing:\n",
    "    - Convert text to lowercase\n",
    "    - Split text into sentences using regex\n",
    "    - Retain sentences even if they do not end with standard punctuation\n",
    "\n",
    "    Args:\n",
    "        text (str): Input text.\n",
    "\n",
    "    Returns:\n",
    "        list: List of cleaned sentences.\n",
    "    \"\"\"\n",
    "    if not isinstance(text, str) or text.strip() == \"\":\n",
    "        return []\n",
    "\n",
    "    text = text.lower().strip()\n",
    "    sentences = re.findall(r'[^.!?]+(?:[.!?â€¦]+)?', text)\n",
    "    cleaned_sentences = [s.strip() for s in sentences if s.strip()]\n",
    "\n",
    "    return cleaned_sentences\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9e2b71b",
   "metadata": {},
   "source": [
    "# Load Dataset for Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ba72dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "std_sen = []\n",
    "gpt1_sen = []  \n",
    "gpt2_sen = []\n",
    "\n",
    "for text in stdset['Essay']:\n",
    "    std_sen.extend(preprocess_sentence(text))\n",
    "\n",
    "for text in gpt1set['Response']:\n",
    "    gpt1_sen.extend(preprocess_sentence(text))\n",
    "\n",
    "for text in gpt2set['Response']:\n",
    "    gpt2_sen.extend(preprocess_sentence(text))\n",
    "\n",
    "\n",
    "# Create DataFrames with text and labels\n",
    "std_df = pd.DataFrame({'text': std_sen, 'label': 0})\n",
    "gpt1_df = pd.DataFrame({'text': gpt1_sen, 'label': 1})\n",
    "gpt2_df = pd.DataFrame({'text': gpt2_sen, 'label': 2})\n",
    "\n",
    "# Combine all data\n",
    "data = pd.concat([std_df, gpt1_df, gpt2_df], ignore_index=True)\n",
    "\n",
    "# Print statistics\n",
    "print(f\"Total student essay paragraphs: {len(std_sen)} (label=0)\")\n",
    "print(f\"Total ChatGPT essay paragraphs: {len(gpt1_sen)} (label=1)\")\n",
    "print(f\"Total ChatGPT knowledge paragraphs: {len(gpt2_sen)} (label=2)\")\n",
    "print(f\"Total combined data: {len(data)}\")\n",
    "\n",
    "# Display first few rows of combined data\n",
    "print(\"\\nFirst few rows of combined data:\")\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "display(data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57714453",
   "metadata": {},
   "source": [
    "# Data Splitting\n",
    "- Training 75%\n",
    "- Validation 5%\n",
    "- Testing 20%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c3b9387",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = train_test_split(\n",
    "    data, test_size=0.2, random_state=42, stratify=data['label']\n",
    ")\n",
    "\n",
    "print(f\"Initial training set: {len(train_data)} samples\")\n",
    "print(f\"Initial test set: {len(test_data)} samples\")\n",
    "print(f\"Initial training distribution: Student={sum(train_data['label']==0)}, ChatGPT={sum(train_data['label']==1)}, ChatGPT_Knowledge={sum(train_data['label']==2)}\")\n",
    "print(f\"Initial test distribution: Student={sum(test_data['label']==0)}, ChatGPT={sum(test_data['label']==1)}, ChatGPT_Knowledge={sum(test_data['label']==2)}\")\n",
    "\n",
    "X_train = train_data[['text']]\n",
    "y_train = train_data['label']\n",
    "\n",
    "undersampler = RandomUnderSampler(random_state=42)\n",
    "X_train_indices = pd.DataFrame({'index': range(len(X_train))})\n",
    "X_resampled_indices, y_resampled = undersampler.fit_resample(X_train_indices, y_train)\n",
    "\n",
    "selected_indices = X_resampled_indices['index'].values\n",
    "\n",
    "balanced_train_data = train_data.iloc[selected_indices].reset_index(drop=True)\n",
    "\n",
    "removed_indices = set(range(len(train_data))) - set(selected_indices)\n",
    "removed_samples = train_data.iloc[list(removed_indices)]\n",
    "\n",
    "test_set = pd.concat([test_data, removed_samples]).reset_index(drop=True)\n",
    "test_set = test_set.sort_values(by='label').reset_index(drop=True)\n",
    "\n",
    "# Create perfectly balanced validation set manually\n",
    "val_per_class = 51  # or any number that divides evenly\n",
    "val_indices = []\n",
    "\n",
    "for label in balanced_train_data['label'].unique():\n",
    "    label_indices = balanced_train_data[balanced_train_data['label'] == label].index[:val_per_class]\n",
    "    val_indices.extend(label_indices)\n",
    "\n",
    "val_set = balanced_train_data.loc[val_indices].reset_index(drop=True)\n",
    "train_set = balanced_train_data.drop(val_indices).reset_index(drop=True)\n",
    "\n",
    "# Sort by label\n",
    "train_set = train_set.sort_values(by='label').reset_index(drop=True)\n",
    "val_set = val_set.sort_values(by='label').reset_index(drop=True)\n",
    "\n",
    "# Print final dataset statistics\n",
    "print(\"\\nAfter undersampling:\")\n",
    "print(f\"Training set: {len(train_set)} samples (Student={sum(train_set['label']==0)}, ChatGPT={sum(train_set['label']==1)}, ChatGPT_Knowledge={sum(train_set['label']==2)})\")\n",
    "print(f\"Validation set: {len(val_set)} samples (Student={sum(val_set['label']==0)}, ChatGPT={sum(val_set['label']==1)}, ChatGPT_Knowledge={sum(val_set['label']==2)})\")\n",
    "print(f\"Test set: {len(test_set)} samples (Student={sum(test_set['label']==0)}, ChatGPT={sum(test_set['label']==1)}, ChatGPT_Knowledge={sum(test_set['label']==2)})\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20bfcf3c",
   "metadata": {},
   "source": [
    "# Initialize BERT Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f04500e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize IndoBERT tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained(\"indobenchmark/indobert-base-p2\")\n",
    "\n",
    "# Tokenize function\n",
    "def tokenize_text(texts, max_length=128):\n",
    "    \"\"\"\n",
    "    Text tokenization using IndoBERT tokenizer.\n",
    "    \n",
    "    Args:\n",
    "        texts (list): List of texts to be tokenized.\n",
    "        max_length (int): Maximum token length.\n",
    "        \n",
    "    Returns:\n",
    "        dict: Tokenized result, including input_ids and attention_mask.\n",
    "    \"\"\"\n",
    "    return tokenizer(\n",
    "        texts,\n",
    "        padding='max_length',\n",
    "        truncation=True,\n",
    "        max_length=max_length,\n",
    "        return_tensors=\"tf\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8dcdc5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize student and ChatGPT essays\n",
    "print(\"Tokenize student essay...\")\n",
    "std_tokens = tokenize_text(std_sen)\n",
    "print(\"Tokenize ChatGPT essay...\")\n",
    "gpt1_tokens = tokenize_text(gpt1_sen)\n",
    "\n",
    "print(\"Tokenize ChatGPT knowledge essay...\")\n",
    "gpt2_tokens = tokenize_text(gpt2_sen)\n",
    "\n",
    "print(\"Tokenize student essay (Training Set)...\")\n",
    "std_tr_tokens = tokenize_text(train_set[train_set['label'] == 0]['text'].tolist())\n",
    "print(\"Tokenize ChatGPT essay (Training Set)...\")\n",
    "gpt1_tr_tokens = tokenize_text(train_set[train_set['label'] == 1]['text'].tolist())\n",
    "print(\"Tokenize ChatGPT knowledge (Training Set)...\")\n",
    "gpt2_tr_tokens = tokenize_text(train_set[train_set['label'] == 2]['text'].tolist())\n",
    "\n",
    "print(\"Tokenize student essay (Validation Set)...\")\n",
    "std_va_tokens = tokenize_text(val_set[val_set['label'] == 0]['text'].tolist())\n",
    "print(\"Tokenize ChatGPT essay (Validation Set)...\")\n",
    "gpt1_va_tokens = tokenize_text(val_set[val_set['label'] == 1]['text'].tolist())\n",
    "print(\"Tokenize ChatGPT knowledge (Validation Set)...\")\n",
    "gpt2_va_tokens = tokenize_text(val_set[val_set['label'] == 2]['text'].tolist())\n",
    "\n",
    "print(\"Tokenize student essay (Test Set)...\")\n",
    "std_te_tokens = tokenize_text(test_set[test_set['label'] == 0]['text'].tolist())\n",
    "print(\"Tokenize ChatGPT essay (Test Set)...\")\n",
    "gpt1_te_tokens = tokenize_text(test_set[test_set['label'] == 1]['text'].tolist())\n",
    "print(\"Tokenize ChatGPT knowledge (Test Set)...\")\n",
    "gpt2_te_tokens = tokenize_text(test_set[test_set['label'] == 2]['text'].tolist())\n",
    "\n",
    "# Display tokenization results (example: Student)\n",
    "print(\"\\nExample of tokenization results:\")\n",
    "print(std_tr_tokens['input_ids'][:3])  # Input token ID\n",
    "print(std_tr_tokens['attention_mask'][:3])  # Attention mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2da4bfc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "std_tr_lengths = [sum(mask) for mask in std_tr_tokens['attention_mask'].numpy()]\n",
    "gpt1_tr_lengths = [sum(mask) for mask in gpt1_tr_tokens['attention_mask'].numpy()]\n",
    "gpt2_tr_lengths = [sum(mask) for mask in gpt2_tr_tokens['attention_mask'].numpy()]\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(std_tr_lengths, bins=30, alpha=0.5, label='Student', color='purple')\n",
    "plt.hist(gpt1_tr_lengths, bins=30, alpha=0.5, label='ChatGPT 1', color='orange')\n",
    "plt.hist(gpt2_tr_lengths, bins=30, alpha=0.5, label='ChatGPT 2', color='green')\n",
    "plt.title('Distribution of Token Lengths')\n",
    "plt.xlabel('Active Token Count')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()\n",
    "print(f\"Average token length for Student: {np.mean(std_tr_lengths):.2f}\")\n",
    "print(f\"Percentage truncated for Student: {sum(l == 128 for l in std_tr_lengths) / len(std_tr_lengths) * 100:.2f}%\")\n",
    "print(f\"Average token length for ChatGPT 1: {np.mean(gpt1_tr_lengths):.2f}\")\n",
    "print(f\"Percentage truncated for ChatGPT 1: {sum(l == 128 for l in gpt1_tr_lengths) / len(gpt1_tr_lengths) * 100:.2f}%\")\n",
    "print(f\"Average token length for ChatGPT 2: {np.mean(gpt2_tr_lengths):.2f}\")\n",
    "print(f\"Percentage truncated for ChatGPT 2: {sum(l == 128 for l in gpt2_tr_lengths) / len(gpt2_tr_lengths) * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0896a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decoding tokens for ensuring correctness\n",
    "sample_text = gpt1_sen[0]\n",
    "sample_tokens = tokenizer.encode(sample_text)\n",
    "print(f\"Sample Text: {sample_text}\")\n",
    "print(f\"Token ID: {sample_tokens}\")\n",
    "print(f\"Token dekode: {tokenizer.decode(sample_tokens)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee363614",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save tokenized data\n",
    "tokenized_data = {\n",
    "    'student_essay': std_tokens,\n",
    "    'chatgpt_essay': gpt1_tokens,\n",
    "    'chatgpt_knowledge': gpt2_tokens\n",
    "}\n",
    "\n",
    "# Save input_ids and attention_mask as numpy arrays\n",
    "tokenized_numpy = {\n",
    "    'student_essay': {\n",
    "        'input_ids': std_tokens['input_ids'].numpy(),\n",
    "        'attention_mask': std_tokens['attention_mask'].numpy()\n",
    "    },\n",
    "    'chatgpt_essay': {\n",
    "        'input_ids': gpt1_tokens ['input_ids'].numpy(),\n",
    "        'attention_mask': gpt1_tokens ['attention_mask'].numpy()\n",
    "    },\n",
    "    'chatgpt_knowledge': {\n",
    "        'input_ids': gpt2_tokens ['input_ids'].numpy(),\n",
    "        'attention_mask': gpt2_tokens ['attention_mask'].numpy()\n",
    "    }\n",
    "}\n",
    "\n",
    "os.makedirs(\"ta_sentence_2\", exist_ok=True)\n",
    "\n",
    "with open('ta_sentence_2/tokenized_data.pkl', 'wb') as f:\n",
    "    pickle.dump(tokenized_numpy, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a26faf74",
   "metadata": {},
   "source": [
    "# Build IndoBERT Semantic Similarity Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88f19b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load IndoBERT model\n",
    "bert_model = TFBertModel.from_pretrained(\"indobenchmark/indobert-base-p2\")\n",
    "\n",
    "# Freeze BERT layers\n",
    "for layer in bert_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Define Bi-Encoder model\n",
    "def model(bert_model):\n",
    "    \"\"\"\n",
    "    Create a Bi-Encoder model with IndoBERT.\n",
    "    \n",
    "    Args:\n",
    "        bert_model (TFBertModel): Base model of IndoBERT.\n",
    "        \n",
    "    Returns:\n",
    "        tf.keras.Model: Bi-Encoder model.\n",
    "    \"\"\"\n",
    "    # Input layer\n",
    "    input_ids = tf.keras.layers.Input(shape=(128,), dtype=tf.int32, name=\"input_ids\")\n",
    "    attention_mask = tf.keras.layers.Input(shape=(128,), dtype=tf.int32, name=\"attention_mask\")\n",
    "    \n",
    "    # Extract CLS token embeddings from IndoBERT\n",
    "    bert_output = bert_model(input_ids, attention_mask=attention_mask)[0][:, 0, :]  # [CLS] token\n",
    "    \n",
    "    # Dense layer for fine-tuning\n",
    "    dense1 = tf.keras.layers.Dense(128, activation=\"relu\")(bert_output)\n",
    "    dropout1 = tf.keras.layers.Dropout(0.1)(dense1)\n",
    "    dense2 = tf.keras.layers.Dense(128, activation=\"relu\")(dropout1)\n",
    "    dropout2 = tf.keras.layers.Dropout(0.1)(dense2)\n",
    "    dense3 = tf.keras.layers.Dense(128)(dropout2)\n",
    "    \n",
    "    # Output normalization (L2 normalization)\n",
    "    normalized_output = tf.nn.l2_normalize(dense3, axis=1)\n",
    "    \n",
    "    # Semantic model\n",
    "    return tf.keras.Model(inputs=[input_ids, attention_mask], outputs=normalized_output)\n",
    "\n",
    "# Build model\n",
    "semantic_model = model(bert_model)\n",
    "\n",
    "# Show model summary\n",
    "print(\"Model Summary:\")\n",
    "semantic_model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6cbf4d6",
   "metadata": {},
   "source": [
    "# Create Contrastive Pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fbc8883",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_contrastive_pairs(student_tokens, chatgpt_tokens_1, chatgpt_tokens_2, max_pairs=None):\n",
    "    \"\"\"\n",
    "    Creates data pairs for contrastive learning with dataset-appropriate quantities.\n",
    "\n",
    "    Args:\n",
    "        student_tokens: Tokenized student text\n",
    "        chatgpt_tokens_1: First set of tokenized ChatGPT text\n",
    "        chatgpt_tokens_2: Second set of tokenized ChatGPT text\n",
    "        max_pairs: Maximum number of pairs (optional). If None, uses all possible combinations.\n",
    "\n",
    "    Returns:\n",
    "        tuple: Dictionary of anchor, positive, negative pairs and labels, and the total number of pairs.\n",
    "    \"\"\"\n",
    "    # Get dataset sizes\n",
    "    n_student = student_tokens['input_ids'].shape[0]\n",
    "    n_chatgpt_1 = chatgpt_tokens_1['input_ids'].shape[0]\n",
    "    n_chatgpt_2 = chatgpt_tokens_2['input_ids'].shape[0]\n",
    "    \n",
    "    # Calculate maximum possible combinations\n",
    "    max_student_pairs = (n_student * (n_student - 1)) // 2  # student-student combinations\n",
    "    max_chatgpt_pairs = (n_chatgpt_1 * (n_chatgpt_1 - 1)) // 2  # chatgpt-chatgpt combinations\n",
    "    max_negative_pairs = n_student * n_chatgpt_2  # student-chatgpt combinations\n",
    "    \n",
    "    # Determine number of pairs to create\n",
    "    if max_pairs is None:\n",
    "        # Use minimum number of positive pairs for balance\n",
    "        n_pos_student = min(max_student_pairs, max_chatgpt_pairs) // 2\n",
    "        n_pos_chatgpt = n_pos_student\n",
    "        # Limit negative pairs to balance with positives\n",
    "        n_neg_pairs = min(max_negative_pairs, 2 * n_pos_student)\n",
    "    else:\n",
    "        # If max_pairs is specified, use that with equal proportions\n",
    "        n_pos_student = max_pairs // 4\n",
    "        n_pos_chatgpt = max_pairs // 4\n",
    "        n_neg_pairs = max_pairs // 2\n",
    "    \n",
    "    # Ensure we don't exceed the maximum possible combinations\n",
    "    n_pos_student = min(n_pos_student, max_student_pairs)\n",
    "    n_pos_chatgpt = min(n_pos_chatgpt, max_chatgpt_pairs)\n",
    "    n_neg_pairs = min(n_neg_pairs, max_negative_pairs)\n",
    "    \n",
    "    # Initialize arrays for data pairs\n",
    "    anchor_input_ids = []\n",
    "    anchor_attention_mask = []\n",
    "    positive_input_ids = []\n",
    "    positive_attention_mask = []\n",
    "    negative_input_ids = []\n",
    "    negative_attention_mask = []\n",
    "    labels = []\n",
    "    \n",
    "    # Generate positive student-student pairs\n",
    "    if n_pos_student > 0:\n",
    "        # Create all possible student-student pairs\n",
    "        student_pairs = [(i, j) for i in range(n_student) for j in range(i+1, n_student)]\n",
    "        # Randomly select pairs\n",
    "        selected_pairs = random.sample(student_pairs, n_pos_student)\n",
    "        \n",
    "        for idx1, idx2 in selected_pairs:\n",
    "            # Anchor (student)\n",
    "            anchor_input_ids.append(student_tokens['input_ids'][idx1])\n",
    "            anchor_attention_mask.append(student_tokens['attention_mask'][idx1])\n",
    "            \n",
    "            # Positive (another student)\n",
    "            positive_input_ids.append(student_tokens['input_ids'][idx2])\n",
    "            positive_attention_mask.append(student_tokens['attention_mask'][idx2])\n",
    "            \n",
    "            # Negative (from ChatGPT)\n",
    "            neg_idx = np.random.choice(n_chatgpt_2)\n",
    "            negative_input_ids.append(chatgpt_tokens_2['input_ids'][neg_idx])\n",
    "            negative_attention_mask.append(chatgpt_tokens_2['attention_mask'][neg_idx])\n",
    "            \n",
    "            # Label (1 for positive pair)\n",
    "            labels.append(1)\n",
    "    \n",
    "    # Generate positive chatgpt-chatgpt pairs\n",
    "    if n_pos_chatgpt > 0:\n",
    "        # Create all possible chatgpt-chatgpt pairs\n",
    "        chatgpt_pairs = [(i, j) for i in range(n_chatgpt_1) for j in range(i+1, n_chatgpt_1)]\n",
    "        # Randomly select pairs\n",
    "        selected_pairs = random.sample(chatgpt_pairs, n_pos_chatgpt)\n",
    "        \n",
    "        for idx1, idx2 in selected_pairs:\n",
    "            # Anchor (ChatGPT 1)\n",
    "            anchor_input_ids.append(chatgpt_tokens_1['input_ids'][idx1])\n",
    "            anchor_attention_mask.append(chatgpt_tokens_1['attention_mask'][idx1])\n",
    "            \n",
    "            # Positive (ChatGPT 2)\n",
    "            positive_input_ids.append(chatgpt_tokens_2['input_ids'][idx2])\n",
    "            positive_attention_mask.append(chatgpt_tokens_2['attention_mask'][idx2])\n",
    "            \n",
    "            # Negative (from Student)\n",
    "            neg_idx = np.random.choice(n_student)\n",
    "            negative_input_ids.append(student_tokens['input_ids'][neg_idx])\n",
    "            negative_attention_mask.append(student_tokens['attention_mask'][neg_idx])\n",
    "            \n",
    "            # Label (1 for positive pair)\n",
    "            labels.append(1)\n",
    "    \n",
    "    # Generate negative student-chatgpt pairs\n",
    "    if n_neg_pairs > 0:\n",
    "        # Create all possible student-chatgpt pairs\n",
    "        negative_pairs = [(i, j) for i in range(n_student) for j in range(n_chatgpt_2)]\n",
    "        # Randomly select pairs\n",
    "        selected_pairs = random.sample(negative_pairs, n_neg_pairs)\n",
    "        \n",
    "        for student_idx, chatgpt_idx in selected_pairs:\n",
    "            # Anchor (Student)\n",
    "            anchor_input_ids.append(student_tokens['input_ids'][student_idx])\n",
    "            anchor_attention_mask.append(student_tokens['attention_mask'][student_idx])\n",
    "            \n",
    "            # Negative (ChatGPT)\n",
    "            negative_input_ids.append(chatgpt_tokens_2['input_ids'][chatgpt_idx])\n",
    "            negative_attention_mask.append(chatgpt_tokens_2['attention_mask'][chatgpt_idx])\n",
    "            \n",
    "            # Positive (another Student different from anchor)\n",
    "            available_pos = [i for i in range(n_student) if i != student_idx]\n",
    "            if available_pos:  # Ensure there are available indices\n",
    "                pos_idx = np.random.choice(available_pos)\n",
    "                positive_input_ids.append(student_tokens['input_ids'][pos_idx])\n",
    "                positive_attention_mask.append(student_tokens['attention_mask'][pos_idx])\n",
    "                \n",
    "                # Label (0 for negative pair)\n",
    "                labels.append(0)\n",
    "    \n",
    "    # Count actual pairs created\n",
    "    actual_pairs = len(labels)\n",
    "    \n",
    "    # Convert to tensors and return\n",
    "    return {\n",
    "        'anchor': {\n",
    "            'input_ids': tf.convert_to_tensor(anchor_input_ids, dtype=tf.int32),\n",
    "            'attention_mask': tf.convert_to_tensor(anchor_attention_mask, dtype=tf.int32)\n",
    "        },\n",
    "        'positive': {\n",
    "            'input_ids': tf.convert_to_tensor(positive_input_ids, dtype=tf.int32),\n",
    "            'attention_mask': tf.convert_to_tensor(positive_attention_mask, dtype=tf.int32)\n",
    "        },\n",
    "        'negative': {\n",
    "            'input_ids': tf.convert_to_tensor(negative_input_ids, dtype=tf.int32),\n",
    "            'attention_mask': tf.convert_to_tensor(negative_attention_mask, dtype=tf.int32)\n",
    "        },\n",
    "        'labels': tf.convert_to_tensor(labels, dtype=tf.float32)\n",
    "    }, actual_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d36a243",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create contrastive pairs\n",
    "std_gpt_tr_pairs, total_pairs_tr = create_contrastive_pairs(std_tr_tokens, gpt1_tr_tokens, gpt2_tr_tokens, max_pairs=250000)\n",
    "std_gpt_va_pairs, total_pairs_va = create_contrastive_pairs(std_va_tokens, gpt1_va_tokens, gpt2_va_tokens, max_pairs=250000)\n",
    "\n",
    "# Show the number of pairs created\n",
    "print(f\"Total contrastive pairs (training) created: {total_pairs_tr}\")\n",
    "print(f\"- Positive pairs student-student: {sum(1 for label in std_gpt_tr_pairs['labels'].numpy() if label == 1)//2}\")\n",
    "print(f\"- Positive pairs chatgpt-chatgpt: {sum(1 for label in std_gpt_tr_pairs['labels'].numpy() if label == 1)//2}\")\n",
    "print(f\"- Negative pairs student-chatgpt: {sum(1 for label in std_gpt_tr_pairs['labels'].numpy() if label == 0)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b7571a6",
   "metadata": {},
   "source": [
    "# Build Triplet Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abc30b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model for training with triplet loss\n",
    "def triplet_model(semantic_model):\n",
    "    \"\"\"\n",
    "    Build a model for training with triplet loss.\n",
    "    \n",
    "    Args:\n",
    "        semantic_model: The semantic similarity model to be trained.\n",
    "        \n",
    "    Returns:\n",
    "         tf.keras.Model: Model for training with triplet loss.\n",
    "    \"\"\"\n",
    "    # Input for anchor, positive, and negative\n",
    "    anchor_input_ids = tf.keras.layers.Input(shape=(128,), dtype=tf.int32, name=\"anchor_input_ids\")\n",
    "    anchor_attention_mask = tf.keras.layers.Input(shape=(128,), dtype=tf.int32, name=\"anchor_attention_mask\")\n",
    "    \n",
    "    positive_input_ids = tf.keras.layers.Input(shape=(128,), dtype=tf.int32, name=\"positive_input_ids\")\n",
    "    positive_attention_mask = tf.keras.layers.Input(shape=(128,), dtype=tf.int32, name=\"positive_attention_mask\")\n",
    "    \n",
    "    negative_input_ids = tf.keras.layers.Input(shape=(128,), dtype=tf.int32, name=\"negative_input_ids\")\n",
    "    negative_attention_mask = tf.keras.layers.Input(shape=(128,), dtype=tf.int32, name=\"negative_attention_mask\")\n",
    "    \n",
    "    # Embedding for anchor, positive, and negative\n",
    "    anchor_embedding = semantic_model([anchor_input_ids, anchor_attention_mask])\n",
    "    positive_embedding = semantic_model([positive_input_ids, positive_attention_mask])\n",
    "    negative_embedding = semantic_model([negative_input_ids, negative_attention_mask])\n",
    "    \n",
    "    # measure cosine similarity\n",
    "    pos_similarity = tf.reduce_sum(anchor_embedding * positive_embedding, axis=1)\n",
    "    neg_similarity = tf.reduce_sum(anchor_embedding * negative_embedding, axis=1)\n",
    "    \n",
    "    # Model output is the similarity score\n",
    "    output = tf.stack([pos_similarity, neg_similarity], axis=1)\n",
    "    \n",
    "    return tf.keras.Model(\n",
    "        inputs=[\n",
    "            anchor_input_ids, anchor_attention_mask,\n",
    "            positive_input_ids, positive_attention_mask,\n",
    "            negative_input_ids, negative_attention_mask\n",
    "        ],\n",
    "        outputs=output\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5659fd85",
   "metadata": {},
   "source": [
    "# Triplet Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32fa9d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Triplet loss function\n",
    "def triplet_loss(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Triplet loss: tunes the network such that\n",
    "the distance between a and p is smaller than the\n",
    "distance between a and n.\n",
    "    \n",
    "    Args:\n",
    "        y_true: not used triplet loss.\n",
    "        y_pred: stack of [positive_similarity, negative_similarity].\n",
    "        \n",
    "    Returns:\n",
    "        tf.Tensor: loss value.\n",
    "    \"\"\"\n",
    "    pos_sim = y_pred[:, 0]\n",
    "    neg_sim = y_pred[:, 1]\n",
    "    margin = 0.5\n",
    "    \n",
    "    # Triplet loss: max(0, margin - (pos_sim - neg_sim))\n",
    "    loss = tf.maximum(0., margin - (pos_sim - neg_sim))\n",
    "    return tf.reduce_mean(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdb09fe5",
   "metadata": {},
   "source": [
    "# Train IndoBERT Semantic Similarity Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f3a84cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build triplet model for student vs ChatGPT essay\n",
    "build_triplet = triplet_model(semantic_model)\n",
    "\n",
    "# Compile model\n",
    "build_triplet.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=2e-5),\n",
    "    loss=triplet_loss\n",
    ")\n",
    "\n",
    "# Training model Student_ChatGPT\n",
    "print(\"Training model...\")\n",
    "history = build_triplet.fit(\n",
    "    x=[\n",
    "        std_gpt_tr_pairs['anchor']['input_ids'],\n",
    "        std_gpt_tr_pairs['anchor']['attention_mask'],\n",
    "        std_gpt_tr_pairs['positive']['input_ids'],\n",
    "        std_gpt_tr_pairs['positive']['attention_mask'],\n",
    "        std_gpt_tr_pairs['negative']['input_ids'],\n",
    "        std_gpt_tr_pairs['negative']['attention_mask']\n",
    "    ],\n",
    "    y=std_gpt_tr_pairs['labels'], \n",
    "    epochs=10,\n",
    "    batch_size=16,\n",
    "    validation_data=(\n",
    "    [\n",
    "        std_gpt_va_pairs['anchor']['input_ids'],\n",
    "        std_gpt_va_pairs['anchor']['attention_mask'],\n",
    "        std_gpt_va_pairs['positive']['input_ids'],\n",
    "        std_gpt_va_pairs['positive']['attention_mask'],\n",
    "        std_gpt_va_pairs['negative']['input_ids'],\n",
    "        std_gpt_va_pairs['negative']['attention_mask']\n",
    "    ],\n",
    "    std_gpt_va_pairs['labels']\n",
    "    ),\n",
    "    callbacks=[\n",
    "        tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=2, restore_best_weights=True)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8a46e7b",
   "metadata": {},
   "source": [
    "# Training History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1e3eb19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training history untuk model Student_ChatGPT\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Model Student_ChatGPT: Training and Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2265bd25",
   "metadata": {},
   "source": [
    "# Generate Embeddings Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c6ae85c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_emb(tokens, model, batch_size=32):\n",
    "    \"\"\"\n",
    "    Generate embeddings using IndoBERT in batches.\n",
    "    \n",
    "    Args:\n",
    "        tokens: Token from text.\n",
    "        model: IndoBERT Semantic Similarity.\n",
    "        batch_size: Number of samples per batch.\n",
    "        \n",
    "    Returns:\n",
    "        np.ndarray: Embeddings.\n",
    "    \"\"\"\n",
    "    embeddings = []\n",
    "    \n",
    "    num_batches = len(tokens['input_ids']) // batch_size + (len(tokens['input_ids']) % batch_size > 0)\n",
    "    \n",
    "    for i in range(num_batches):\n",
    "        start_idx = i * batch_size\n",
    "        end_idx = min((i + 1) * batch_size, len(tokens['input_ids']))\n",
    "\n",
    "        batch_input_ids = tokens['input_ids'][start_idx:end_idx]\n",
    "        batch_attention_mask = tokens['attention_mask'][start_idx:end_idx]\n",
    "        \n",
    "        batch_embeddings = model([batch_input_ids, batch_attention_mask])\n",
    "        \n",
    "        embeddings.append(batch_embeddings)\n",
    "    \n",
    "    return np.concatenate(embeddings, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1bee85e",
   "metadata": {},
   "source": [
    "# Cosine Similarity Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "048d0402",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cos_sim(embedding1, embedding2):\n",
    "    \"\"\"\n",
    "    Calculate similarity score using standard cosine similarity.\n",
    "    \n",
    "    Args:\n",
    "        embedding1: First embedding (input text)\n",
    "        embedding2: Second embedding (reference)\n",
    "        \n",
    "    Returns:\n",
    "        float: Average cosine similarity score\n",
    "    \"\"\"\n",
    "    embedding1_norm = tf.nn.l2_normalize(embedding1, axis=-1)\n",
    "    embedding2_norm = tf.nn.l2_normalize(embedding2, axis=-1)\n",
    "    \n",
    "    similarities = tf.matmul(embedding1_norm, tf.transpose(embedding2_norm))\n",
    "    similarities = tf.reshape(similarities, [-1])\n",
    "\n",
    "    avg_similarity = tf.reduce_mean(similarities).numpy()\n",
    "    return avg_similarity\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4be2da6b",
   "metadata": {},
   "source": [
    "# Generate Embeddings (All Text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70124035",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate embeddings for all text\n",
    "print(\"Generating embeddings for Student Essay (all text)...\")\n",
    "std_emb = gen_emb(std_tokens, semantic_model, batch_size=32)\n",
    "print(\"Generating embeddings for ChatGPT Essay (all text)...\")\n",
    "gpt1_emb = gen_emb(gpt1_tokens, semantic_model, batch_size=32)\n",
    "print(\"Generating embeddings for ChatGPT Knowledge (all text)...\")\n",
    "gpt2_emb = gen_emb(gpt2_tokens, semantic_model, batch_size=32)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fc3a0ce",
   "metadata": {},
   "source": [
    "# Measure Similarity Score (All Text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5735fd5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "std_std_sim_scores = []\n",
    "std_gpt1_sim_scores = []\n",
    "std_gpt2_sim_scores = []\n",
    "\n",
    "for emb in std_emb:\n",
    "    avg_similarity = cos_sim(tf.expand_dims(emb, 0), std_emb)\n",
    "    std_std_sim_scores.append(avg_similarity)\n",
    "\n",
    "    avg_similarity = cos_sim(tf.expand_dims(emb, 0), gpt1_emb)\n",
    "    std_gpt1_sim_scores.append(avg_similarity)\n",
    "\n",
    "    avg_similarity = cos_sim(tf.expand_dims(emb, 0), gpt2_emb)\n",
    "    std_gpt2_sim_scores.append(avg_similarity)\n",
    "\n",
    "gpt1_std_sim_scores = []\n",
    "gpt1_gpt1_sim_scores = []\n",
    "gpt1_gpt2_sim_scores = []\n",
    "\n",
    "for emb in gpt1_emb:\n",
    "    avg_similarity = cos_sim(tf.expand_dims(emb, 0), std_emb)\n",
    "    gpt1_std_sim_scores.append(avg_similarity)\n",
    "\n",
    "    avg_similarity = cos_sim(tf.expand_dims(emb, 0), gpt1_emb)\n",
    "    gpt1_gpt1_sim_scores.append(avg_similarity)\n",
    "\n",
    "    avg_similarity = cos_sim(tf.expand_dims(emb, 0), gpt2_emb)\n",
    "    gpt1_gpt2_sim_scores.append(avg_similarity)\n",
    "\n",
    "std_sim_scores = np.array([\n",
    "    std_std_sim_scores, \n",
    "    std_gpt1_sim_scores,\n",
    "    std_gpt2_sim_scores\n",
    "])\n",
    "\n",
    "gpt_sim_scores = np.array([\n",
    "    gpt1_std_sim_scores, \n",
    "    gpt1_gpt1_sim_scores,\n",
    "    gpt1_gpt2_sim_scores\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a79d747f",
   "metadata": {},
   "source": [
    "# Visualization of Similarity Score (All Text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43555acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 6))\n",
    "\n",
    "student_student_color = \"#9747FF\"  \n",
    "student_chatgpt_color = \"#FCD19C\"  \n",
    "chatgpt_chatgpt_color = \"#FFA629\"  \n",
    "chatgpt_student_color = \"#E4CCFF\"  \n",
    "\n",
    "# Subplot 1: Student Essay\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.scatter(range(len(std_std_sim_scores)), std_std_sim_scores, \n",
    "            label='Student-Student', color=student_student_color, s=70, alpha=0.8, edgecolor='black', linewidth=0.5)\n",
    "plt.scatter(range(len(std_gpt1_sim_scores)), std_gpt1_sim_scores, \n",
    "            label='Student-ChatGPT', color=student_chatgpt_color, s=70, alpha=0.8, edgecolor='black', linewidth=0.5)\n",
    "plt.title('Student Essay', fontsize=14, fontweight='bold')\n",
    "plt.ylim(-1.05, 1.05)  \n",
    "plt.yticks(np.arange(-1, 1.1, 0.1))\n",
    "plt.legend(fontsize=10)\n",
    "plt.grid(True, linestyle='--', alpha=0.3)\n",
    "\n",
    "# Subplot 2: ChatGPT Essay\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.scatter(range(len(gpt1_std_sim_scores)), gpt1_std_sim_scores, \n",
    "            label='ChatGPT-Student', color=chatgpt_student_color, s=70, alpha=0.8, edgecolor='black', linewidth=0.5)\n",
    "plt.scatter(range(len(gpt1_gpt1_sim_scores)), gpt1_gpt1_sim_scores, \n",
    "            label='ChatGPT-ChatGPT', color=chatgpt_chatgpt_color, s=70, alpha=0.8, edgecolor='black', linewidth=0.5)\n",
    "plt.title('ChatGPT Essay', fontsize=14, fontweight='bold')\n",
    "plt.ylim(-1.05, 1.05)  \n",
    "plt.yticks(np.arange(-1, 1.1, 0.1))\n",
    "plt.legend(fontsize=10)\n",
    "plt.grid(True, linestyle='--', alpha=0.3)\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.scatter(range(len(std_gpt2_sim_scores)), std_gpt2_sim_scores, \n",
    "            label='Student-Knowledge ChatGPT', color=chatgpt_student_color, s=70, alpha=0.8, edgecolor='black', linewidth=0.5)\n",
    "plt.scatter(range(len(gpt1_gpt2_sim_scores)), gpt1_gpt2_sim_scores, \n",
    "            label='ChatGPT-Knowledge ChatGPT', color=chatgpt_chatgpt_color, s=70, alpha=0.8, edgecolor='black', linewidth=0.5)\n",
    "plt.title('ChatGPT Knowledge', fontsize=14, fontweight='bold')\n",
    "plt.ylim(-1.05, 1.05)  \n",
    "plt.yticks(np.arange(-1, 1.1, 0.1))\n",
    "plt.legend(fontsize=10)\n",
    "plt.grid(True, linestyle='--', alpha=0.3)\n",
    "\n",
    "plt.suptitle('Similarity Scores Comparison All Text', fontsize=16, fontweight='bold', y=0.98, ha='center')\n",
    "plt.tight_layout()\n",
    "plt.subplots_adjust(top=0.85)  \n",
    "\n",
    "os.makedirs('ta_sentence_2/images', exist_ok=True)\n",
    "plt.savefig('ta_sentence_2/images/similarity_scores_comparison(all).png', dpi=300, bbox_inches='tight')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e94ca615",
   "metadata": {},
   "source": [
    "# Generate Embeddings (Test Set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "234dea03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate embeddings for data test\n",
    "print(\"Generating embeddings for Student (test set)...\")\n",
    "std_te_emb = gen_emb(std_te_tokens, semantic_model, batch_size=32)\n",
    "print(\"Generating embeddings for ChatGPT (test set)...\")\n",
    "gpt1_te_emb = gen_emb(gpt1_te_tokens, semantic_model, batch_size=32)\n",
    "print(\"Generating embeddings for ChatGPT Knowledge (test set)...\")\n",
    "gpt2_te_emb = gen_emb(gpt2_te_tokens, semantic_model, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25a78f7e",
   "metadata": {},
   "source": [
    "# Measure Similarity Score (Test Set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "926b4188",
   "metadata": {},
   "outputs": [],
   "source": [
    "std_std_te_sim_scores = []\n",
    "std_gpt1_te_sim_scores = []\n",
    "std_gpt2_te_sim_scores = []\n",
    "for emb in std_te_emb:\n",
    "    avg_similarity = cos_sim(tf.expand_dims(emb, 0), std_emb)\n",
    "    std_std_te_sim_scores.append(avg_similarity)\n",
    "\n",
    "    avg_similarity = cos_sim(tf.expand_dims(emb, 0), gpt1_emb)\n",
    "    std_gpt1_te_sim_scores.append(avg_similarity)\n",
    "\n",
    "    avg_similarity = cos_sim(tf.expand_dims(emb, 0), gpt2_emb)\n",
    "    std_gpt2_te_sim_scores.append(avg_similarity)\n",
    "\n",
    "gpt1_std_te_sim_scores = []\n",
    "gpt1_gpt1_te_sim_scores = []\n",
    "gpt1_gpt2_te_sim_scores = []\n",
    "\n",
    "for emb in gpt1_te_emb:\n",
    "    avg_similarity = cos_sim(tf.expand_dims(emb, 0), std_emb)\n",
    "    gpt1_std_te_sim_scores.append(avg_similarity)\n",
    "\n",
    "    avg_similarity = cos_sim(tf.expand_dims(emb, 0), gpt1_emb)\n",
    "    gpt1_gpt1_te_sim_scores.append(avg_similarity)\n",
    "    \n",
    "    avg_similarity = cos_sim(tf.expand_dims(emb, 0), gpt2_emb)\n",
    "    gpt1_gpt2_te_sim_scores.append(avg_similarity)\n",
    "\n",
    "\n",
    "std_te_sim_scores = np.array([\n",
    "    std_std_te_sim_scores, \n",
    "    std_gpt1_te_sim_scores,\n",
    "    std_gpt2_te_sim_scores\n",
    "])\n",
    "\n",
    "gpt_te_sim_scores = np.array([\n",
    "    gpt1_std_te_sim_scores, \n",
    "    gpt1_gpt1_te_sim_scores,\n",
    "    gpt1_gpt2_te_sim_scores\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c47a3a6b",
   "metadata": {},
   "source": [
    "# Similarity Text Breakdown (Test Set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ea813fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pairs = []\n",
    "pd.set_option('display.max_colwidth', None)  \n",
    "pd.set_option('display.width', 1000)        \n",
    "pd.set_option('display.max_rows', None)      \n",
    "\n",
    "for i, student_text in enumerate(std_sen):\n",
    "    if i >= len(std_te_emb):\n",
    "        continue\n",
    "        \n",
    "    student_embedding = tf.expand_dims(std_te_emb[i], 0)\n",
    "\n",
    "    for j in range(len(gpt1_sen)):\n",
    "        if j >= len(gpt1_te_emb):\n",
    "            continue\n",
    "\n",
    "        chatgpt1_embedding = tf.expand_dims(gpt1_te_emb[j], 0)\n",
    "        similarity = cos_sim(student_embedding, chatgpt1_embedding)\n",
    "        \n",
    "        test_pairs.append({\n",
    "            'student_idx': i,\n",
    "            'chatgpt_idx': j,\n",
    "            'student_text': student_text,\n",
    "            'chatgpt_text': gpt1_sen[j],\n",
    "            'similarity_score': similarity\n",
    "        })\n",
    "\n",
    "sorted_pairs = sorted(test_pairs, key=lambda x: x['similarity_score'], reverse=True)\n",
    "\n",
    "result_v1 = sorted_pairs[:5]\n",
    "\n",
    "df_v1 = pd.DataFrame(result_v1)[['student_text', 'chatgpt_text', 'similarity_score']]\n",
    "df_v1.columns = ['Student Essay', 'ChatGPT Essay', 'Similarity Score']\n",
    "\n",
    "print(\"=== 1: Standard ===\")\n",
    "display(df_v1)\n",
    "\n",
    "used_student_indices_v2 = set()\n",
    "used_chatgpt_indices_v2 = set()\n",
    "result_v2 = []\n",
    "\n",
    "for pair in sorted_pairs:\n",
    "    if (pair['student_idx'] in used_student_indices_v2 or \n",
    "        pair['chatgpt_idx'] in used_chatgpt_indices_v2):\n",
    "        continue\n",
    "    result_v2.append(pair)\n",
    "    used_student_indices_v2.add(pair['student_idx'])\n",
    "    used_chatgpt_indices_v2.add(pair['chatgpt_idx'])\n",
    "    if len(result_v2) >= 5:\n",
    "        break\n",
    "\n",
    "df_v2 = pd.DataFrame(result_v2)[['student_text', 'chatgpt_text', 'similarity_score']]\n",
    "df_v2.columns = ['Student Essay', 'ChatGPT Essay', 'Similarity Score']\n",
    "\n",
    "print(\"=== 2: Unique ===\")\n",
    "display(df_v2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "180d3c91",
   "metadata": {},
   "source": [
    "# Visualization of Similarity Score (Test Set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebe10ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 6))\n",
    "\n",
    "student_student_color = \"#9747FF\"  \n",
    "student_chatgpt_color = \"#FCD19C\"  \n",
    "chatgpt_chatgpt_color = \"#FFA629\"  \n",
    "chatgpt_student_color = \"#E4CCFF\"  \n",
    "\n",
    "# Subplot 1: Student\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.scatter(range(len(std_std_te_sim_scores)), std_std_te_sim_scores, \n",
    "            label='Student-Student', color=student_student_color, s=70, alpha=0.8, edgecolor='black', linewidth=0.5)\n",
    "plt.scatter(range(len(std_gpt1_te_sim_scores)), std_gpt1_te_sim_scores, \n",
    "            label='Student-ChatGPT', color=student_chatgpt_color, s=70, alpha=0.8, edgecolor='black', linewidth=0.5)\n",
    "plt.title('Student Essay', fontsize=14, fontweight='bold')\n",
    "plt.ylim(-1.05, 1.05)  \n",
    "plt.yticks(np.arange(-1, 1.1, 0.1))\n",
    "plt.legend(fontsize=10)\n",
    "plt.grid(True, linestyle='--', alpha=0.3)\n",
    "\n",
    "# Subplot 2: ChatGPT\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.scatter(range(len(gpt1_std_te_sim_scores)), gpt1_std_te_sim_scores, \n",
    "            label='ChatGPT-Student', color=chatgpt_student_color, s=70, alpha=0.8, edgecolor='black', linewidth=0.5)\n",
    "plt.scatter(range(len(gpt1_gpt1_te_sim_scores)), gpt1_gpt1_te_sim_scores, \n",
    "            label='ChatGPT-ChatGPT', color=chatgpt_chatgpt_color, s=70, alpha=0.8, edgecolor='black', linewidth=0.5)\n",
    "plt.title('ChatGPT Essay', fontsize=14, fontweight='bold')\n",
    "plt.ylim(-1.05, 1.05)  \n",
    "plt.yticks(np.arange(-1, 1.1, 0.1))\n",
    "plt.legend(fontsize=10)\n",
    "plt.grid(True, linestyle='--', alpha=0.3)\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.scatter(range(len(std_gpt2_te_sim_scores)), std_gpt2_te_sim_scores, \n",
    "            label='Student-Knowledge ChatGPT', color=chatgpt_student_color, s=70, alpha=0.8, edgecolor='black', linewidth=0.5)\n",
    "plt.scatter(range(len(gpt1_gpt2_te_sim_scores)), gpt1_gpt2_te_sim_scores, \n",
    "            label='ChatGPT-Knowledge ChatGPT', color=chatgpt_chatgpt_color, s=70, alpha=0.8, edgecolor='black', linewidth=0.5)\n",
    "plt.title('ChatGPT Knowledge', fontsize=14, fontweight='bold')\n",
    "plt.ylim(-1.05, 1.05)  \n",
    "plt.yticks(np.arange(-1, 1.1, 0.1))\n",
    "plt.legend(fontsize=10)\n",
    "plt.grid(True, linestyle='--', alpha=0.3)\n",
    "\n",
    "plt.suptitle('Similarity Scores Comparison (Test Set)', fontsize=16, fontweight='bold', y=0.98, ha='center')\n",
    "plt.tight_layout()\n",
    "plt.subplots_adjust(top=0.85)  \n",
    "\n",
    "plt.savefig('ta_sentence_2/images/similarity_scores_comparison(test).png', dpi=300, bbox_inches='tight')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e69aad25",
   "metadata": {},
   "source": [
    "# Generate Embeddings (Training & Validation Sets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e13ecd56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate embeddings for training and validation sets\n",
    "print(\"Generating embeddings for Student (training set)...\")\n",
    "std_tr_emb = gen_emb(std_tr_tokens, semantic_model, batch_size=32)\n",
    "print(\"Generating embeddings for ChatGPT (training set)...\")\n",
    "gpt1_tr_emb = gen_emb(gpt1_tr_tokens, semantic_model, batch_size=32)\n",
    "print(\"Generating embeddings for ChatGPT knowledge (training set)...\")\n",
    "gpt2_tr_emb = gen_emb(gpt2_tr_tokens, semantic_model, batch_size=32)\n",
    "\n",
    "print(\"Generating embeddings for Student (validation set)...\")\n",
    "std_va_emb = gen_emb(std_va_tokens, semantic_model, batch_size=32)\n",
    "print(\"Generating embeddings for ChatGPT (validation set)...\")\n",
    "gpt1_va_emb = gen_emb(gpt1_va_tokens, semantic_model, batch_size=32)\n",
    "print(\"Generating embeddings for ChatGPT knowledge (validation set)...\")\n",
    "gpt2_va_emb = gen_emb(gpt2_va_tokens, semantic_model, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4db1cec6",
   "metadata": {},
   "source": [
    "# Measure Similarity Score (Training & Validation Sets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc390814",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training set\n",
    "std_std_tr_sim_scores = []\n",
    "std_gpt1_tr_sim_scores = []\n",
    "std_gpt2_tr_sim_scores = []\n",
    "for emb in std_tr_emb:\n",
    "    avg_similarity = cos_sim(tf.expand_dims(emb, 0), std_emb)\n",
    "    std_std_tr_sim_scores.append(avg_similarity)\n",
    "\n",
    "    avg_similarity = cos_sim(tf.expand_dims(emb, 0), gpt1_emb)\n",
    "    std_gpt1_tr_sim_scores.append(avg_similarity)\n",
    "\n",
    "    avg_similarity = cos_sim(tf.expand_dims(emb, 0), gpt2_emb)\n",
    "    std_gpt2_tr_sim_scores.append(avg_similarity)\n",
    "\n",
    "gpt1_std_tr_sim_scores = []\n",
    "gpt1_gpt1_tr_sim_scores = []\n",
    "gpt1_gpt2_tr_sim_scores = []\n",
    "\n",
    "for emb in gpt1_tr_emb:\n",
    "    avg_similarity = cos_sim(tf.expand_dims(emb, 0), std_emb)\n",
    "    gpt1_std_tr_sim_scores.append(avg_similarity)\n",
    "\n",
    "    avg_similarity = cos_sim(tf.expand_dims(emb, 0), gpt1_emb)\n",
    "    gpt1_gpt1_tr_sim_scores.append(avg_similarity)\n",
    "\n",
    "    avg_similarity = cos_sim(tf.expand_dims(emb, 0), gpt2_emb)\n",
    "    gpt1_gpt2_tr_sim_scores.append(avg_similarity)\n",
    "\n",
    "std_tr_sim_scores = np.array([\n",
    "    std_std_tr_sim_scores, \n",
    "    std_gpt1_tr_sim_scores,\n",
    "    std_gpt2_tr_sim_scores\n",
    "])\n",
    "\n",
    "gpt_tr_sim_scores = np.array([\n",
    "    gpt1_std_tr_sim_scores, \n",
    "    gpt1_gpt1_tr_sim_scores,\n",
    "    gpt1_gpt2_tr_sim_scores\n",
    "])\n",
    "\n",
    "# Validation set\n",
    "std_std_va_sim_scores = []\n",
    "std_gpt1_va_sim_scores = []\n",
    "std_gpt2_va_sim_scores = []\n",
    "for emb in std_va_emb:\n",
    "    avg_similarity = cos_sim(tf.expand_dims(emb, 0), std_emb)\n",
    "    std_std_va_sim_scores.append(avg_similarity)\n",
    "\n",
    "    avg_similarity = cos_sim(tf.expand_dims(emb, 0), gpt1_emb)\n",
    "    std_gpt1_va_sim_scores.append(avg_similarity)\n",
    "\n",
    "    avg_similarity = cos_sim(tf.expand_dims(emb, 0), gpt2_emb)\n",
    "    std_gpt2_va_sim_scores.append(avg_similarity)\n",
    "\n",
    "gpt1_std_va_sim_scores = []\n",
    "gpt1_gpt1_va_sim_scores = []\n",
    "gpt1_gpt2_va_sim_scores = []\n",
    "for emb in gpt1_va_emb:\n",
    "    avg_similarity = cos_sim(tf.expand_dims(emb, 0), std_emb)\n",
    "    gpt1_std_va_sim_scores.append(avg_similarity)\n",
    "\n",
    "    avg_similarity = cos_sim(tf.expand_dims(emb, 0), gpt1_emb)\n",
    "    gpt1_gpt1_va_sim_scores.append(avg_similarity)\n",
    "\n",
    "    avg_similarity = cos_sim(tf.expand_dims(emb, 0), gpt2_emb)\n",
    "    gpt1_gpt2_va_sim_scores.append(avg_similarity)\n",
    "\n",
    "std_va_sim_scores = np.array([\n",
    "    std_std_va_sim_scores, \n",
    "    std_gpt1_va_sim_scores,\n",
    "    std_gpt2_va_sim_scores\n",
    "])\n",
    "\n",
    "gpt_va_sim_scores = np.array([\n",
    "    gpt1_std_va_sim_scores, \n",
    "    gpt1_gpt1_va_sim_scores,\n",
    "    gpt1_gpt2_va_sim_scores\n",
    "])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "564ab90c",
   "metadata": {},
   "source": [
    "# Define Linguistic Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7408bf6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def linguistic_features(text):\n",
    "    \"\"\"\n",
    "    Features extraction from text:\n",
    "    1.\tLexical Diversity\n",
    "    2.\tTotal words in the essay\n",
    "    3.\tTotal unique words*\n",
    "    4.\tModals\n",
    "    5.\tStopwords ratio*\n",
    "\n",
    "    \n",
    "    Args:\n",
    "        text (str): Input text.\n",
    "        \n",
    "    Returns:\n",
    "        dict: Linguistic features.\n",
    "    \"\"\"\n",
    "    words = re.findall(r'\\b\\w+\\b', text)\n",
    "    sentences = re.split(r'[.!?]', text)\n",
    "    sentences = [s.strip() for s in sentences if s.strip()]\n",
    "\n",
    "    word_count = len(words)\n",
    "    unique_count = len(set(words))\n",
    "    \n",
    "    ld = (unique_count / word_count * 100) if word_count > 0 else 0\n",
    "    \n",
    "    # Load modals from corpus file\n",
    "    modals = set()\n",
    "    if os.path.exists('corpus/Indonesian_Manually_Tagged_Corpus_ID.tsv'):\n",
    "        with open('corpus/Indonesian_Manually_Tagged_Corpus_ID.tsv', 'r', encoding='utf-8') as f:\n",
    "            for line in f:\n",
    "                if line.strip():\n",
    "                    parts = line.strip().split('\\t')\n",
    "                    if len(parts) >= 2 and parts[1] == 'MD':\n",
    "                        modals.add(parts[0].lower())\n",
    "    \n",
    "    # Count modals in text\n",
    "    modal_count = sum(1 for word in words if word.lower() in modals)\n",
    "    \n",
    "    # Load stopwords from file\n",
    "    stopwords = set()\n",
    "    if os.path.exists('corpus/stopwords.txt'):\n",
    "        with open('corpus/stopwords.txt', 'r', encoding='utf-8') as f:\n",
    "            for line in f:\n",
    "                stopwords.add(line.strip())\n",
    "    \n",
    "    # Calculate stopword ratio\n",
    "    stopword_count = sum(1 for word in words if word.lower() in stopwords)\n",
    "    stopword_ratio = (stopword_count / word_count * 100) if word_count > 0 else 0\n",
    "\n",
    "    return {\n",
    "        'lexical_diversity': ld,\n",
    "        'total_words': word_count,\n",
    "        'total_unique_words': unique_count,\n",
    "        'modals': modal_count,\n",
    "        'stopwords_ratio': stopword_ratio,\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dbb7a06",
   "metadata": {},
   "source": [
    "# Features Extraction (All Text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f72b33be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature extraction for Student and ChatGPT essays\n",
    "print(\"Features extraction for Student...\")\n",
    "std_features = [linguistic_features(text) for text in std_sen]\n",
    "\n",
    "print(\"Features extraction for ChatGPT...\")\n",
    "gpt_features = [linguistic_features(text) for text in gpt1_sen]\n",
    "\n",
    "\n",
    "# convert\n",
    "std_features_df = pd.DataFrame(std_features)\n",
    "gpt_features_df = pd.DataFrame(gpt_features)\n",
    "\n",
    "\n",
    "# Show the first few rows of the features DataFrames\n",
    "print(\"\\nStudent Linguistic Features:\")\n",
    "display(std_features_df.head())\n",
    "\n",
    "print(\"\\nChatGPT Linguistic Features:\")\n",
    "display(gpt_features_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46f2ccff",
   "metadata": {},
   "source": [
    "# Normalize Linguistic Features (All Text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2425049c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine features into a single DataFrame\n",
    "all_features = pd.concat([std_features_df, gpt_features_df], axis=0)\n",
    "\n",
    "# Normalize features\n",
    "scaler = StandardScaler()\n",
    "normalized_features = scaler.fit_transform(all_features)\n",
    "\n",
    "# Separate normalized features back into student and ChatGPT\n",
    "n_student = len(std_features_df)\n",
    "n_chatgpt = len(gpt_features_df)\n",
    "\n",
    "std_features_norm = normalized_features[:n_student]\n",
    "gpt_features_norm = normalized_features[n_student:n_student + n_chatgpt]\n",
    "\n",
    "print(\"Student features after normalization:\")\n",
    "print(std_features_norm[:5])\n",
    "\n",
    "print(\"ChatGPT features after normalization:\")\n",
    "print(gpt_features_norm[:5])\n",
    "\n",
    "# Save scaler for later inference\n",
    "try:\n",
    "    with open('ta_sentence_2/scaler_linguistic.pkl', 'wb') as f:\n",
    "        pickle.dump(scaler, f)\n",
    "    print(\"Scaler saved successfully.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error saving scaler: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87746ebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add labels to features\n",
    "std_features_df['label'] = 'Student Essay'\n",
    "gpt_features_df['label'] = 'ChatGPT Essay'\n",
    "\n",
    "# Combine datasets\n",
    "combined_features = pd.concat([std_features_df, gpt_features_df], axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe4e7238",
   "metadata": {},
   "source": [
    "# Visualize Linguistic Features (All Texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6376d746",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(30, 20))\n",
    "for i, feature in enumerate([\n",
    "    'lexical_diversity',\n",
    "    'total_words',\n",
    "    'total_unique_words',\n",
    "    'modals',\n",
    "    'stopwords_ratio',\n",
    "]):\n",
    "    plt.subplot(2, 4, i+1)\n",
    "    sns.violinplot(x='label', y=feature, data=combined_features, inner=None, alpha=0.6, linewidth=1.5)\n",
    "    sns.boxplot(x='label', y=feature, data=combined_features, width=0.4, \n",
    "                saturation=1, showfliers=True, color='white', linewidth=1.5)\n",
    "    sns.stripplot(x='label', y=feature, data=combined_features, color='red', alpha=0.2, size=6, jitter=True, dodge=True)\n",
    "    plt.title(f'Distribution of {feature.replace(\"_\", \" \").title()}', fontsize=16)\n",
    "    plt.xticks(fontsize=16)\n",
    "    plt.yticks(fontsize=16)\n",
    "\n",
    "plt.suptitle('Linguistic Features All Text', fontsize=32, fontweight='bold', y=0.98)\n",
    "plt.tight_layout(pad=3.0)\n",
    "\n",
    "plt.savefig('ta_sentence_2/images/linguistic_features_comparison(all).png', dpi=300, bbox_inches='tight')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01b34c0f",
   "metadata": {},
   "source": [
    "# Feature Extraction (Training, Validation, & Test Sets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4549d8cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature extraction for Student and ChatGPT essays\n",
    "print(\"Features extraction for Student (training set)...\")\n",
    "std_tr_features = [linguistic_features(text) for text in train_set[train_set['label'] == 0]['text'].tolist()]\n",
    "print(\"Features extraction for ChatGPT (training set)...\")\n",
    "gpt_tr_features = [linguistic_features(text) for text in train_set[train_set['label'] == 1]['text'].tolist()]\n",
    "\n",
    "print(\"Features extraction for Student (validation set)...\")\n",
    "std_va_features = [linguistic_features(text) for text in val_set[val_set['label'] == 0]['text'].tolist()]\n",
    "print(\"Features extraction for ChatGPT (validation set)...\")\n",
    "gpt_va_features = [linguistic_features(text) for text in val_set[val_set['label'] == 1]['text'].tolist()]\n",
    "\n",
    "print(\"Features extraction for Student (test set)...\")\n",
    "std_te_features = [linguistic_features(text) for text in test_set[test_set['label'] == 0]['text'].tolist()]\n",
    "print(\"Features extraction for ChatGPT (test set)...\")\n",
    "gpt_te_features = [linguistic_features(text) for text in test_set[test_set['label'] == 1]['text'].tolist()]\n",
    "\n",
    "# convert\n",
    "std_tr_features_df = pd.DataFrame(std_tr_features)\n",
    "gpt_tr_features_df = pd.DataFrame(gpt_tr_features)\n",
    "\n",
    "std_va_features_df = pd.DataFrame(std_va_features)\n",
    "gpt_va_features_df = pd.DataFrame(gpt_va_features)\n",
    "\n",
    "std_te_features_df = pd.DataFrame(std_te_features)\n",
    "gpt_te_features_df = pd.DataFrame(gpt_te_features)\n",
    "\n",
    "#Show the first few rows of the features DataFrames\n",
    "print(\"\\nStudent Linguistic Features (Test Set):\")\n",
    "display(std_te_features_df.head())\n",
    "\n",
    "print(\"\\nChatGPT Linguistic Features (Test Set):\")\n",
    "display(gpt_te_features_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bec2426",
   "metadata": {},
   "outputs": [],
   "source": [
    "std_tr_features_df.shape, gpt_tr_features_df.shape, std_va_features_df.shape, gpt_va_features_df.shape, std_te_features_df.shape, gpt_te_features_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfa34444",
   "metadata": {},
   "source": [
    "# Normalize Linguistic Features (Training, Validation, & Test Sets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd41dd78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine features into a single DataFrame\n",
    "all_tr_features = pd.concat([std_tr_features_df, gpt_tr_features_df], axis=0)\n",
    "all_va_features = pd.concat([std_va_features_df, gpt_va_features_df], axis=0)\n",
    "all_te_features = pd.concat([std_te_features_df, gpt_te_features_df], axis=0)\n",
    "\n",
    "# Normalize features\n",
    "scaler = StandardScaler()\n",
    "normalized_tr_features = scaler.fit_transform(all_tr_features)\n",
    "normalized_va_features = scaler.fit_transform(all_va_features)\n",
    "normalized_te_features = scaler.fit_transform(all_te_features)\n",
    "\n",
    "# Separate normalized features back into student and ChatGPT\n",
    "n_student_tr = len(std_tr_features_df)\n",
    "n_chatgpt_tr = len(gpt_tr_features_df)\n",
    "\n",
    "n_student_va = len(std_va_features_df)\n",
    "n_chatgpt_va = len(gpt_va_features_df)\n",
    "\n",
    "n_student_te = len(std_te_features_df)\n",
    "n_chatgpt_te = len(gpt_te_features_df)\n",
    "\n",
    "std_tr_features_norm = normalized_tr_features[:n_student_tr]\n",
    "gpt_tr_features_norm = normalized_tr_features[n_student_tr:n_student_tr + n_chatgpt_tr]\n",
    "\n",
    "std_va_features_norm = normalized_va_features[:n_student_va]\n",
    "gpt_va_features_norm = normalized_va_features[n_student_va:n_student_va + n_chatgpt_va]\n",
    "\n",
    "std_te_features_norm = normalized_te_features[:n_student_te]\n",
    "gpt_te_features_norm = normalized_te_features[n_student_te:n_student_te + n_chatgpt_te]\n",
    "\n",
    "print(\"Student features after normalization (training):\")\n",
    "print(std_tr_features_norm[:5])\n",
    "\n",
    "print(\"ChatGPT features after normalization (training):\")\n",
    "print(gpt_tr_features_norm[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8a768f1",
   "metadata": {},
   "source": [
    "# Visualize Linguistic Features (Data Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b9e1289",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add labels to features\n",
    "std_tr_features_df['label'] = 'Student Essay'\n",
    "gpt_tr_features_df['label'] = 'ChatGPT Essay'\n",
    "\n",
    "# Combine datasets\n",
    "combined_tr_features = pd.concat([std_tr_features_df, gpt_tr_features_df], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77ab6dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_func():\n",
    "    plt.figure(figsize=(30, 20))\n",
    "    for i, feature in enumerate([\n",
    "    'lexical_diversity',\n",
    "    'total_words',\n",
    "    'total_unique_words',\n",
    "    'modals',\n",
    "    'stopwords_ratio',\n",
    "]):\n",
    "        plt.subplot(2, 4, i+1)\n",
    "        sns.violinplot(x='label', y=feature, data=combined_tr_features, inner=None, alpha=0.6, linewidth=1.5)\n",
    "        sns.boxplot(x='label', y=feature, data=combined_tr_features, width=0.4, \n",
    "                saturation=1, showfliers=True, color='white', linewidth=1.5)\n",
    "        sns.stripplot(x='label', y=feature, data=combined_tr_features, color='red', alpha=0.2, size=6, jitter=True, dodge=True)\n",
    "        plt.title(f'Distribution of {feature.replace(\"_\", \" \").title()}', fontsize=16)\n",
    "        plt.xticks(fontsize=16)\n",
    "        plt.yticks(fontsize=16)\n",
    "\n",
    "new_func()\n",
    "\n",
    "plt.suptitle('Linguistic Features Data Test', fontsize=32, fontweight='bold', y=0.98)\n",
    "plt.tight_layout(pad=3.0)\n",
    "\n",
    "plt.savefig('ta_sentence_2/images/linguistic_features_comparison(test).png', dpi=300, bbox_inches='tight')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6801f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check dimensions of your embedding arrays\n",
    "print(\"std_te_emb shape:\", std_te_emb.shape)\n",
    "print(\"gpt1_te_emb shape:\", gpt1_te_emb.shape)\n",
    "\n",
    "\n",
    "# Print shapes of the resulting similarity scores\n",
    "print(\"std_std_te_sim_scores shape:\", np.array(std_std_te_sim_scores).shape)\n",
    "print(\"std_gpt1_te_sim_scores shape:\", np.array(std_gpt1_te_sim_scores).shape)\n",
    "print(\"gpt1_std_te_sim_scores shape:\", np.array(gpt1_std_te_sim_scores).shape)\n",
    "print(\"gpt1_gpt1_te_sim_scores shape:\", np.array(gpt1_gpt1_te_sim_scores).shape)\n",
    "\n",
    "# Check shapes of the combined arrays\n",
    "print(\"std_te_sim_scores shape:\", std_te_sim_scores.shape)\n",
    "print(\"gpt_te_sim_scores shape:\", gpt_te_sim_scores.shape)\n",
    "\n",
    "print(\"std_te_features_norm shape:\", std_te_features_norm.shape)\n",
    "print(\"gpt1_te_features_norm shape:\", gpt_te_features_norm.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b35ccbca",
   "metadata": {},
   "source": [
    "# Data Preparation for Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90390e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine embeddings for model 1 (already correct)\n",
    "emb_tr_features = np.vstack([std_tr_emb, gpt1_tr_emb])\n",
    "emb_va_features = np.vstack([std_va_emb, gpt1_va_emb])\n",
    "emb_te_features = np.vstack([std_te_emb, gpt1_te_emb])\n",
    "\n",
    "std_tr_features_selected = std_tr_features_norm\n",
    "gpt_tr_features_selected = gpt_tr_features_norm\n",
    "\n",
    "std_va_features_selected = std_va_features_norm\n",
    "gpt_va_features_selected = gpt_va_features_norm\n",
    "\n",
    "std_te_features_selected = std_te_features_norm\n",
    "gpt_te_features_selected = gpt_te_features_norm\n",
    "\n",
    "linguistic_tr_features = np.vstack([\n",
    "    std_tr_features_selected,\n",
    "    gpt_tr_features_selected\n",
    "])\n",
    "linguistic_va_features = np.vstack([\n",
    "    std_va_features_selected,\n",
    "    gpt_va_features_selected\n",
    "])\n",
    "linguistic_te_features = np.vstack([\n",
    "    std_te_features_selected,\n",
    "    gpt_te_features_selected\n",
    "])\n",
    "\n",
    "std_tr_sim_scores_transposed = std_tr_sim_scores.T \n",
    "gpt_tr_sim_scores_transposed = gpt_tr_sim_scores.T\n",
    "similarity_tr_scores = np.vstack([\n",
    "    std_tr_sim_scores_transposed,\n",
    "    gpt_tr_sim_scores_transposed,\n",
    "])\n",
    "\n",
    "std_va_sim_scores_transposed = std_va_sim_scores.T \n",
    "gpt_va_sim_scores_transposed = gpt_va_sim_scores.T\n",
    "similarity_va_scores = np.vstack([\n",
    "    std_va_sim_scores_transposed,\n",
    "    gpt_va_sim_scores_transposed,\n",
    "])\n",
    "std_te_sim_scores_transposed = std_te_sim_scores.T \n",
    "gpt_te_sim_scores_transposed = gpt_te_sim_scores.T\n",
    "similarity_te_scores = np.vstack([\n",
    "    std_te_sim_scores_transposed,\n",
    "    gpt_te_sim_scores_transposed,\n",
    "])\n",
    "\n",
    "# Create labels\n",
    "std_tr_labels = np.zeros(len(train_set[train_set['label'] == 0]))\n",
    "gpt_tr_labels = np.ones(len(train_set[train_set['label'] == 1]))\n",
    "tr_labels = np.hstack([std_tr_labels, gpt_tr_labels])\n",
    "\n",
    "# Validation set labels\n",
    "std_va_labels = np.zeros(len(val_set[val_set['label'] == 0]))\n",
    "gpt_va_labels = np.ones(len(val_set[val_set['label'] == 1]))\n",
    "va_labels = np.hstack([std_va_labels, gpt_va_labels])\n",
    "\n",
    "# Test set labels\n",
    "std_te_labels = np.zeros(len(test_set[test_set['label'] == 0]))\n",
    "gpt_te_labels = np.ones(len(test_set[test_set['label'] == 1]))\n",
    "te_labels = np.hstack([std_te_labels, gpt_te_labels])\n",
    "\n",
    "tr_labels = tr_labels.astype(int)\n",
    "va_labels = va_labels.astype(int)\n",
    "te_labels = te_labels.astype(int)\n",
    "\n",
    "# Verify shapes\n",
    "print(f\"emb_te_features shape: {emb_te_features.shape}\")\n",
    "print(f\"linguistic_te_features shape: {linguistic_te_features.shape}\")\n",
    "print(f\"similarity_te_scores shape: {similarity_te_scores.shape}\")\n",
    "print(f\"te_labels shape: {te_labels.shape}\")\n",
    "\n",
    "print(f\"emb_te_features value: {emb_te_features[:5]}\")\n",
    "print(f\"linguistic_te_features value: {linguistic_te_features[:5]}\")\n",
    "print(f\"similarity_te_scores value: {similarity_te_scores[:5]}\")\n",
    "print(f\"te_labels value: {te_labels[:5]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "973e31a6",
   "metadata": {},
   "source": [
    "# Build Classification Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7df763d",
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_input = tf.keras.layers.Input(\n",
    "    shape=(128,),\n",
    "    dtype=tf.float32, \n",
    "    name=\"embeddings\"\n",
    ")\n",
    "\n",
    "sim_score_input = tf.keras.layers.Input(\n",
    "    shape=(3,), \n",
    "    dtype=tf.float32, \n",
    "    name=\"similarity_score\"\n",
    ")\n",
    "\n",
    "linguistic_input = tf.keras.layers.Input(\n",
    "    shape=(5,),\n",
    "    dtype=tf.float32, \n",
    "    name=\"linguistic_features\"\n",
    ")\n",
    "\n",
    "emb_dense = tf.keras.layers.Dense(128, activation=\"relu\")(emb_input)\n",
    "sim_dense = tf.keras.layers.Dense(16, activation=\"relu\")(sim_score_input)\n",
    "lin_dense = tf.keras.layers.Dense(64, activation=\"relu\")(linguistic_input)\n",
    "\n",
    "combined = tf.keras.layers.Concatenate()([emb_dense, sim_dense, lin_dense])\n",
    "\n",
    "x = tf.keras.layers.Dense(128, activation=\"relu\")(combined)\n",
    "x = tf.keras.layers.Dropout(0.2)(x)\n",
    "x = tf.keras.layers.Dense(64, activation=\"relu\")(x)\n",
    "output = tf.keras.layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "\n",
    "classifier = tf.keras.Model(\n",
    "    inputs=[emb_input, sim_score_input, linguistic_input],\n",
    "    outputs=output,\n",
    "    name=\"text_classifier\"\n",
    ")\n",
    "\n",
    "classifier.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n",
    "    loss=\"binary_crossentropy\",\n",
    "    metrics=[\"accuracy\", tf.keras.metrics.Precision(), tf.keras.metrics.Recall(), tf.keras.metrics.AUC()]\n",
    ")\n",
    "\n",
    "classifier.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcde60e7",
   "metadata": {},
   "source": [
    "# Create Data Input for Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c743699",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_inputs = {\n",
    "    \"embeddings\": emb_tr_features,\n",
    "    \"similarity_score\": similarity_tr_scores,\n",
    "    \"linguistic_features\": linguistic_tr_features\n",
    "}\n",
    "\n",
    "val_inputs = {\n",
    "    \"embeddings\": emb_va_features,\n",
    "    \"similarity_score\": similarity_va_scores,\n",
    "    \"linguistic_features\": linguistic_va_features\n",
    "}\n",
    "\n",
    "\n",
    "test_inputs = {\n",
    "    \"embeddings\": emb_te_features,\n",
    "    \"similarity_score\": similarity_te_scores,\n",
    "    \"linguistic_features\": linguistic_te_features\n",
    "}\n",
    "\n",
    "train_labels = tr_labels\n",
    "val_labels = va_labels\n",
    "test_labels = te_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "766a3990",
   "metadata": {},
   "source": [
    "# Train Classification Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95ab9e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training classifier\n",
    "print(\"Training Classification Model...\")\n",
    "history_classifier = classifier.fit(\n",
    "    train_inputs,\n",
    "    train_labels,\n",
    "    validation_data=(val_inputs, val_labels),\n",
    "    epochs=30,\n",
    "    batch_size=16,\n",
    "    callbacks=[\n",
    "        tf.keras.callbacks.EarlyStopping(\n",
    "            monitor='val_loss',\n",
    "            patience=2,\n",
    "            restore_best_weights=True\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Plot training history\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history_classifier.history['loss'], label='Training Loss')\n",
    "plt.plot(history_classifier.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Model Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history_classifier.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history_classifier.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title('Model Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79cd11e4",
   "metadata": {},
   "source": [
    "# Evaluation Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e8a5d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine only training and validation inputs and labels (excluding test data)\n",
    "combined_inputs = {\n",
    "    \"embeddings\": np.concatenate([train_inputs[\"embeddings\"], val_inputs[\"embeddings\"]]),\n",
    "    \"similarity_score\": np.concatenate([train_inputs[\"similarity_score\"], val_inputs[\"similarity_score\"]]),\n",
    "    \"linguistic_features\": np.concatenate([train_inputs[\"linguistic_features\"], val_inputs[\"linguistic_features\"]])\n",
    "}\n",
    "combined_labels = np.concatenate([train_labels, val_labels])\n",
    "\n",
    "# Make predictions on combined training and validation data\n",
    "print(\"Making predictions on training and validation data...\")\n",
    "combined_predictions = classifier.predict(combined_inputs)\n",
    "\n",
    "# Calculate ROC curve and plot\n",
    "print(\"Generating ROC curve...\")\n",
    "fpr, tpr, _ = roc_curve(combined_labels, combined_predictions)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc:.4f})')\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve (Training + Validation)')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.savefig('ta_sentence_2/images/roc_curve (train_val).png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Calculate performance at different thresholds\n",
    "print(\"Analyzing threshold performance...\")\n",
    "percentiles = np.linspace(0, 100, num=101)\n",
    "sensitivity_data = []  \n",
    "specificity_data = [] \n",
    "intersection_points = []\n",
    "\n",
    "for p in percentiles:\n",
    "    threshold = np.percentile(combined_predictions, p)\n",
    "    predictions_binary = (combined_predictions >= threshold).astype(int)\n",
    "    tn, fp, fn, tp = confusion_matrix(combined_labels, predictions_binary).ravel()\n",
    "    \n",
    "    sensitivity = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "    specificity = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
    "    \n",
    "    sensitivity_data.append(sensitivity)\n",
    "    specificity_data.append(specificity)\n",
    "    \n",
    "    # Identify where sensitivity and specificity are approximately equal\n",
    "    if np.isclose(sensitivity, specificity, atol=1e-2):\n",
    "        intersection_points.append((p, threshold, sensitivity))\n",
    "\n",
    "# Plot sensitivity-specificity tradeoff\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.plot(percentiles, sensitivity_data, label='Sensitivity (True Positive Rate)', color='blue', lw=2, linestyle='--')\n",
    "plt.plot(percentiles, specificity_data, label='Specificity (True Negative Rate)', color='green', lw=2)\n",
    "\n",
    "# Highlight balanced points\n",
    "for p, threshold, rate in intersection_points:\n",
    "    plt.scatter(p, rate, color='red')\n",
    "\n",
    "plt.xlabel('Percentile Score Threshold')\n",
    "plt.ylabel('Rate')\n",
    "plt.title('Sensitivity-Specificity Tradeoff (Training + Validation)')\n",
    "plt.legend(loc=\"best\")\n",
    "plt.savefig('ta_sentence_2/images/tradeoff_with_intersections (train_val).png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"Threshold points with equal sensitivity and specificity:\")\n",
    "for p, threshold, rate in intersection_points:\n",
    "    print(f\"Percentile: {p:.1f}, Threshold: {threshold:.4f}, Rate: {rate:.4f}\")\n",
    "\n",
    "if intersection_points:\n",
    "    _, optimal_threshold, _ = intersection_points[0]\n",
    "else:\n",
    "    optimal_threshold = np.percentile(combined_predictions, 50)\n",
    "\n",
    "print(f\"Selected optimal threshold: {optimal_threshold:.4f}\")\n",
    "\n",
    "# Apply optimal threshold for final predictions\n",
    "combined_predictions_binary = (combined_predictions >= optimal_threshold).astype(int)\n",
    "\n",
    "# Generate confusion matrix with custom styling\n",
    "cm_combined = confusion_matrix(combined_labels, combined_predictions_binary)\n",
    "\n",
    "# Define custom colors for confusion matrix\n",
    "colors = np.array([\n",
    "    [\"#9747FF\", \"#FCD19C\"],  \n",
    "    [\"#E4CCFF\", \"#FFA629\"]\n",
    "])\n",
    "\n",
    "# Visualize confusion matrix\n",
    "plt.figure(figsize=(10, 8))\n",
    "rows, cols = cm_combined.shape\n",
    "row_ind, col_ind = np.meshgrid(np.arange(rows), np.arange(cols), indexing='ij')\n",
    "\n",
    "for i in range(rows):\n",
    "    for j in range(cols):\n",
    "        plt.fill_between([j, j+1], [rows-i-1, rows-i-1], [rows-i, rows-i], color=colors[i, j])\n",
    "        plt.text(j+0.5, rows-i-0.5, str(cm_combined[i, j]), ha='center', va='center', \n",
    "                 color='black', fontsize=14, fontweight='bold')\n",
    "\n",
    "plt.title('Confusion Matrix (Training + Validation)', fontsize=16)\n",
    "plt.xlabel('Predicted', fontsize=14)\n",
    "plt.ylabel('Actual', fontsize=14)\n",
    "plt.xticks([0.5, 1.5], ['Student', 'ChatGPT'], fontsize=12)\n",
    "plt.yticks([0.5, 1.5], ['ChatGPT', 'Student'], fontsize=12)\n",
    "plt.xlim(0, 2)\n",
    "plt.ylim(0, 2)\n",
    "plt.savefig('ta_sentence_2/images/confusion_matrix(train_val).png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Classification report\n",
    "print(\"\\nDetailed Classification Report (Training + Validation):\")\n",
    "print(classification_report(combined_labels, combined_predictions_binary, target_names=['Student', 'ChatGPT']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2348fee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on test data only\n",
    "print(\"Making predictions on test dataset...\")\n",
    "test_predictions = classifier.predict(test_inputs)\n",
    "\n",
    "test_predictions_binary = (test_predictions >= optimal_threshold).astype(int)\n",
    "\n",
    "cm_test = confusion_matrix(test_labels, test_predictions_binary)\n",
    "\n",
    "# Define custom colors for confusion matrix\n",
    "colors = np.array([\n",
    "    [\"#9747FF\", \"#FCD19C\"],  \n",
    "    [\"#E4CCFF\", \"#FFA629\"]\n",
    "])\n",
    "\n",
    "# Visualize confusion matrix for test data\n",
    "plt.figure(figsize=(10, 8))\n",
    "rows, cols = cm_test.shape\n",
    "row_ind, col_ind = np.meshgrid(np.arange(rows), np.arange(cols), indexing='ij')\n",
    "\n",
    "for i in range(rows):\n",
    "    for j in range(cols):\n",
    "        plt.fill_between([j, j+1], [rows-i-1, rows-i-1], [rows-i, rows-i], color=colors[i, j])\n",
    "        plt.text(j+0.5, rows-i-0.5, str(cm_test[i, j]), ha='center', va='center', \n",
    "                 color='black', fontsize=14, fontweight='bold')\n",
    "\n",
    "plt.title('Confusion Matrix (Test Dataset)', fontsize=16)\n",
    "plt.xlabel('Predicted', fontsize=14)\n",
    "plt.ylabel('Actual', fontsize=14)\n",
    "plt.xticks([0.5, 1.5], ['Student', 'ChatGPT'], fontsize=12)\n",
    "plt.yticks([0.5, 1.5], ['ChatGPT', 'Student'], fontsize=12)\n",
    "plt.xlim(0, 2)\n",
    "plt.ylim(0, 2)\n",
    "plt.savefig('ta_sentence_2/images/confusion_matrix (test set).png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Classification report for test data\n",
    "print(\"\\nDetailed Classification Report (test set):\")\n",
    "print(classification_report(test_labels, test_predictions_binary, target_names=['Student', 'ChatGPT']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efeb0f8a",
   "metadata": {},
   "source": [
    "# Misclassified Essay Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70450c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "misclassified_students = []\n",
    "misclassified_chatgpt = []\n",
    "test_actual_texts = test_set['text'].values\n",
    "similarity_scores = test_inputs['similarity_score']\n",
    "\n",
    "for i, (actual, pred) in enumerate(zip(test_labels, test_predictions_binary)):\n",
    "    if actual == 0 and pred == 1:\n",
    "        student_idx = i\n",
    "        most_similar_chatgpt = None\n",
    "        highest_similarity = -1\n",
    "        avg_similarity_to_chatgpt = similarity_scores[i][1]\n",
    "        for j, gpt_text in enumerate(gpt1_sen):\n",
    "            if j < len(gpt1_te_emb):\n",
    "                student_embedding = tf.expand_dims(std_te_emb[student_idx], 0) if student_idx < len(std_te_emb) else None\n",
    "                chatgpt1_embedding = tf.expand_dims(gpt1_te_emb[j], 0)\n",
    "                \n",
    "                if student_embedding is not None:\n",
    "                    similarity = cos_sim(student_embedding, chatgpt1_embedding)\n",
    "                    \n",
    "                    if similarity > highest_similarity:\n",
    "                        highest_similarity = similarity\n",
    "                        most_similar_chatgpt = gpt1_sen[j]\n",
    "        \n",
    "        misclassified_students.append({\n",
    "            'Type': 'False Positive',\n",
    "            'Text': test_actual_texts[i], \n",
    "            'Model Confidence': test_predictions[i][0],\n",
    "            'Avg. Similarity': avg_similarity_to_chatgpt,\n",
    "            'Most Similar Text': most_similar_chatgpt,\n",
    "            'Similarity Score': highest_similarity\n",
    "        })\n",
    "    elif actual == 1 and pred == 0:\n",
    "        chatgpt_idx = i\n",
    "        most_similar_student = None\n",
    "        highest_similarity = -1\n",
    "        avg_similarity_to_student = similarity_scores[i][0]\n",
    "        for j, std_text in enumerate(std_sen):\n",
    "            if j < len(std_te_emb):\n",
    "                chatgpt1_embedding = tf.expand_dims(gpt1_te_emb[chatgpt_idx-len(std_te_emb)], 0) if chatgpt_idx >= len(std_te_emb) else None\n",
    "                student_embedding = tf.expand_dims(std_te_emb[j], 0)\n",
    "                \n",
    "                if chatgpt1_embedding is not None:\n",
    "                    similarity = cos_sim(chatgpt1_embedding, student_embedding)\n",
    "                    \n",
    "                    if similarity > highest_similarity:\n",
    "                        highest_similarity = similarity\n",
    "                        most_similar_student = std_sen[j]\n",
    "        \n",
    "        misclassified_chatgpt.append({\n",
    "            'Type': 'False Negative', \n",
    "            'Text': test_actual_texts[i], \n",
    "            'Model Confidence': 1 - test_predictions[i][0],\n",
    "            'Avg. Similarity': avg_similarity_to_student,\n",
    "            'Most Similar Text': most_similar_student,\n",
    "            'Similarity Score': highest_similarity\n",
    "        })\n",
    "\n",
    "sorted_misclassified_students = sorted(\n",
    "    misclassified_students, \n",
    "    key=lambda x: (x['Similarity Score'], x['Avg. Similarity'], x['Model Confidence']),\n",
    "    reverse=True\n",
    ")\n",
    "\n",
    "sorted_misclassified_chatgpt = sorted(\n",
    "    misclassified_chatgpt, \n",
    "    key=lambda x: (x['Similarity Score'], x['Avg. Similarity'], x['Model Confidence']),\n",
    "    reverse=True\n",
    ")\n",
    "\n",
    "print(\"Top 3 Student Essays Misclassified as ChatGPT (by Similarity):\")\n",
    "display(pd.DataFrame(sorted_misclassified_students).head(3))\n",
    "\n",
    "print(\"\\nTop 2 ChatGPT Essays Misclassified as Student (by Similarity):\")\n",
    "display(pd.DataFrame(sorted_misclassified_chatgpt).head(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79de9803",
   "metadata": {},
   "source": [
    "# Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00047f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "reference_embeddings = {\n",
    "    'embeddings_std_sen': {\n",
    "        'embeddings': std_emb,\n",
    "    },\n",
    "    'embeddings_gpt1_sen': {\n",
    "        'embeddings': gpt1_emb,\n",
    "    },\n",
    "    'embeddings_gpt2_sen': {\n",
    "        'embeddings': gpt2_emb,\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43fe7285",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('ta_sentence_2'):\n",
    "    os.makedirs('ta_sentence_2')\n",
    "\n",
    "with open('ta_sentence_2/reference_embeddings.pkl', 'wb') as f:\n",
    "    pickle.dump(reference_embeddings, f)\n",
    "\n",
    "semantic_model.save('ta_sentence_2/semantic_model.h5')\n",
    "classifier.save('ta_sentence_2/classification_model.h5')\n",
    "\n",
    "tokenizer.save_pretrained('ta_sentence_2/tokenizer')\n",
    "\n",
    "with open(\"ta_sentence_2/scaler_linguistic.pkl\", \"wb\") as f:\n",
    "    pickle.dump(scaler, f)\n",
    "\n",
    "print(\"Model and configuration successfully saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b96d55d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext watermark\n",
    "%watermark\n",
    "%watermark -iv --gpu"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
