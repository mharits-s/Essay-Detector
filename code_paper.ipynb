{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cfe276a1",
   "metadata": {},
   "source": [
    "# Import Libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c088b44f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from transformers import BertTokenizer, TFBertModel\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import os\n",
    "import re\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.metrics import confusion_matrix, classification_report, roc_curve, auc\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2cfd2a4",
   "metadata": {},
   "source": [
    "# Load Essay Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a23b8d43",
   "metadata": {},
   "outputs": [],
   "source": [
    "stdset = pd.read_excel(\"datasets/esai_siswa_24_25.xlsx\")\n",
    "gptset = pd.read_csv(\"datasets/esai_gpt_24_25.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "52788db7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 327 entries, 0 to 326\n",
      "Data columns (total 4 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   teks_esai     327 non-null    object\n",
      " 1   nama          327 non-null    object\n",
      " 2   asal_sekolah  327 non-null    object\n",
      " 3   tahun         327 non-null    int64 \n",
      "dtypes: int64(1), object(3)\n",
      "memory usage: 10.3+ KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>teks_esai</th>\n",
       "      <th>nama</th>\n",
       "      <th>asal_sekolah</th>\n",
       "      <th>tahun</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>P3KTAS: Menciptakan Persatuan dalam Masyarakat...</td>\n",
       "      <td>Achmad Muchasan Nafi</td>\n",
       "      <td>SMA PRIBADI BANDUNG</td>\n",
       "      <td>2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Apakah Anda memiliki teman atau saudara yang b...</td>\n",
       "      <td>Achmad Muchasan Nafi</td>\n",
       "      <td>SMA PRIBADI BANDUNG</td>\n",
       "      <td>2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dengan adanya perbedaan budaya tersebut banyak...</td>\n",
       "      <td>Achmad Muchasan Nafi</td>\n",
       "      <td>SMA PRIBADI BANDUNG</td>\n",
       "      <td>2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Kasus diskriminasi terbesar di Indonesia lainn...</td>\n",
       "      <td>Achmad Muchasan Nafi</td>\n",
       "      <td>SMA PRIBADI BANDUNG</td>\n",
       "      <td>2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Diskriminasi merupakan salah satu faktor yang ...</td>\n",
       "      <td>Achmad Muchasan Nafi</td>\n",
       "      <td>SMA PRIBADI BANDUNG</td>\n",
       "      <td>2024</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           teks_esai                  nama  \\\n",
       "0  P3KTAS: Menciptakan Persatuan dalam Masyarakat...  Achmad Muchasan Nafi   \n",
       "1  Apakah Anda memiliki teman atau saudara yang b...  Achmad Muchasan Nafi   \n",
       "2  Dengan adanya perbedaan budaya tersebut banyak...  Achmad Muchasan Nafi   \n",
       "3  Kasus diskriminasi terbesar di Indonesia lainn...  Achmad Muchasan Nafi   \n",
       "4  Diskriminasi merupakan salah satu faktor yang ...  Achmad Muchasan Nafi   \n",
       "\n",
       "          asal_sekolah  tahun  \n",
       "0  SMA PRIBADI BANDUNG   2024  \n",
       "1  SMA PRIBADI BANDUNG   2024  \n",
       "2  SMA PRIBADI BANDUNG   2024  \n",
       "3  SMA PRIBADI BANDUNG   2024  \n",
       "4  SMA PRIBADI BANDUNG   2024  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stdset.info()\n",
    "stdset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b97e9f99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 273 entries, 0 to 272\n",
      "Data columns (total 1 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   Response  273 non-null    object\n",
      "dtypes: object(1)\n",
      "memory usage: 2.3+ KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>harmoni keberagaman: jalan menuju kejayaan ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>di tengah bising derap langkah modernitas yang...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>kilas balik pada sejarah panjang negeri ini me...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>namun, mengelola keragaman tidaklah semudah me...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>salah satu modal utama untuk mencapai kejayaan...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Response\n",
       "0   harmoni keberagaman: jalan menuju kejayaan ba...\n",
       "1  di tengah bising derap langkah modernitas yang...\n",
       "2  kilas balik pada sejarah panjang negeri ini me...\n",
       "3  namun, mengelola keragaman tidaklah semudah me...\n",
       "4  salah satu modal utama untuk mencapai kejayaan..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gptset.info()\n",
    "gptset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0bfe94ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    \"\"\"\n",
    "    Preprocessing text:\n",
    "    - Convert text to lowercase\n",
    "    - Cleaning up excess whitespace\n",
    "    - Keeps the text as a whole paragraph\n",
    "    \n",
    "    Args:\n",
    "        text (str): input text.\n",
    "        \n",
    "    Returns:\n",
    "        str: the processed text or None if invalid.\n",
    "    \"\"\"\n",
    "    if not isinstance(text, str) or text.strip() == \"\":\n",
    "        return None\n",
    "    \n",
    "    text = text.lower().strip()\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    text = text.replace('_x000d_', '')\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e46f67eb",
   "metadata": {},
   "source": [
    "# Essay Informations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "099891a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statistics per Author:\n",
      "                                           nama  single_sentence  multiple_sentences  total_texts\n",
      "                     Syarifuddin Muhammad Wahib                2                  28           30\n",
      "                       Nandra Nadhesya Larasati                2                  18           20\n",
      "                               Arif Nurfadlilah                5                  15           20\n",
      "                        Nadia Izzati Firmansyah                1                  19           20\n",
      "                                Dewi Tyas Utami                1                  18           19\n",
      "                                   Levi Linardi                1                  18           19\n",
      "                                 Shulhan Tasdiq                2                  15           17\n",
      "                      Sekar Anggita Widyatamaka                1                  16           17\n",
      "                             Belva Aqila Irwani                1                  15           16\n",
      "                             Eldo Rerick Rahman                2                  14           16\n",
      " Arabel Eltara Gabrielie Partangiang Tampubolon                1                  14           15\n",
      "                           Savril Ilmi Ramadhan                1                  14           15\n",
      "             Ryuken Archaez Fadzillah Al Caesar                1                  13           14\n",
      "                        Muhammad Rifky Ramadhan                1                  13           14\n",
      "                          Rafifah Asylah Ashadi                1                  12           13\n",
      "                           Achmad Muchasan Nafi                1                  12           13\n",
      "                                       Kharaida                1                  12           13\n",
      "                        Muhammad Rifky Ramadhan                2                  11           13\n",
      "Arabel El Tara Gabrielie Partangiang Tampubolon                1                  11           12\n",
      "                        Nabila Farrel Ratnadita                1                  10           11\n",
      "\n",
      "Student Summary:\n",
      "Total authors: 20\n",
      "Total texts: 327\n",
      "Total single sentences: 29\n",
      "Total multiple sentences: 298\n",
      "Minimum multiple sentences per author: 10\n",
      "Maximum multiple sentences per author: 28\n",
      "Mean multiple sentences per author: 14.90\n"
     ]
    }
   ],
   "source": [
    "# Count number of texts per author\n",
    "author_counts = stdset.groupby('nama')['teks_esai'].count().sort_values(ascending=False)\n",
    "total_authors = len(author_counts)\n",
    "\n",
    "# Count sentences in each text\n",
    "def count_sentences(text):\n",
    "    if not isinstance(text, str):\n",
    "        return 0\n",
    "    # Clean text first using existing preprocess_text function\n",
    "    text = preprocess_text(text)\n",
    "    if not text:\n",
    "        return 0\n",
    "    # Split by common sentence endings\n",
    "    sentences = re.split('[.!?]+', text)\n",
    "    # Remove empty strings\n",
    "    sentences = [s.strip() for s in sentences if s.strip()]\n",
    "    return len(sentences)\n",
    "\n",
    "# Apply sentence counting to teks_esai\n",
    "sentence_counts = stdset['teks_esai'].apply(count_sentences)\n",
    "\n",
    "# Calculate statistics\n",
    "single_sentence = sum(sentence_counts == 1)\n",
    "multiple_sentences = sum(sentence_counts > 1)\n",
    "total_texts = len(sentence_counts)\n",
    "\n",
    "# Create a DataFrame to show statistics per author\n",
    "author_stats = pd.DataFrame()\n",
    "author_stats['nama'] = author_counts.index\n",
    "author_stats['single_sentence'] = [sum(sentence_counts[stdset['nama'] == author] == 1) for author in author_stats['nama']]\n",
    "author_stats['multiple_sentences'] = [sum(sentence_counts[stdset['nama'] == author] > 1) for author in author_stats['nama']]\n",
    "author_stats['total_texts'] = author_counts.values\n",
    "\n",
    "# Display the table\n",
    "print(\"Statistics per Author:\")\n",
    "print(author_stats.to_string(index=False))\n",
    "\n",
    "# Calculate and display summary statistics\n",
    "print(\"\\nStudent Summary:\")\n",
    "print(f\"Total authors: {total_authors}\")\n",
    "print(f\"Total texts: {total_texts}\")\n",
    "print(f\"Total single sentences: {single_sentence}\")\n",
    "print(f\"Total multiple sentences: {multiple_sentences}\")\n",
    "print(f\"Minimum multiple sentences per author: {author_stats['multiple_sentences'].min()}\")\n",
    "print(f\"Maximum multiple sentences per author: {author_stats['multiple_sentences'].max()}\")\n",
    "mean_multiple_sentences = author_stats['multiple_sentences'].mean()\n",
    "print(f\"Mean multiple sentences per author: {mean_multiple_sentences:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "36f83960",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Statistics for 2024:\n",
      "Total authors: 10\n",
      "Total texts: 154\n",
      "Total single sentences: 12\n",
      "Total multiple sentences: 142\n",
      "Minimum multiple sentences per author: 12\n",
      "Maximum multiple sentences per author: 19\n",
      "Mean multiple sentences per author: 14.20\n",
      "\n",
      "Statistics for 2025:\n",
      "Total authors: 10\n",
      "Total texts: 173\n",
      "Total single sentences: 17\n",
      "Total multiple sentences: 156\n",
      "Minimum multiple sentences per author: 10\n",
      "Maximum multiple sentences per author: 28\n",
      "Mean multiple sentences per author: 15.60\n"
     ]
    }
   ],
   "source": [
    "# Create subsets based on year\n",
    "author_stats_2024 = author_stats[author_stats['nama'].isin(stdset[stdset['tahun'] == 2024]['nama'].unique())]\n",
    "author_stats_2025 = author_stats[author_stats['nama'].isin(stdset[stdset['tahun'] == 2025]['nama'].unique())]\n",
    "\n",
    "# Print statistics for 2024\n",
    "print(\"\\nStatistics for 2024:\")\n",
    "print(f\"Total authors: {len(author_stats_2024)}\")\n",
    "print(f\"Total texts: {author_stats_2024['total_texts'].sum()}\")\n",
    "print(f\"Total single sentences: {author_stats_2024['single_sentence'].sum()}\")\n",
    "print(f\"Total multiple sentences: {author_stats_2024['multiple_sentences'].sum()}\")\n",
    "print(f\"Minimum multiple sentences per author: {author_stats_2024['multiple_sentences'].min()}\")\n",
    "print(f\"Maximum multiple sentences per author: {author_stats_2024['multiple_sentences'].max()}\")\n",
    "print(f\"Mean multiple sentences per author: {author_stats_2024['multiple_sentences'].mean():.2f}\")\n",
    "\n",
    "# Print statistics for 2025  \n",
    "print(\"\\nStatistics for 2025:\")\n",
    "print(f\"Total authors: {len(author_stats_2025)}\")\n",
    "print(f\"Total texts: {author_stats_2025['total_texts'].sum()}\")\n",
    "print(f\"Total single sentences: {author_stats_2025['single_sentence'].sum()}\")\n",
    "print(f\"Total multiple sentences: {author_stats_2025['multiple_sentences'].sum()}\")\n",
    "print(f\"Minimum multiple sentences per author: {author_stats_2025['multiple_sentences'].min()}\")\n",
    "print(f\"Maximum multiple sentences per author: {author_stats_2025['multiple_sentences'].max()}\")\n",
    "print(f\"Mean multiple sentences per author: {author_stats_2025['multiple_sentences'].mean():.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9d74cf20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ChatGPT Summary:\n",
      "Total texts: 273\n",
      "Total single sentences: 20\n",
      "Total multiple sentences: 253\n",
      "Minimum multiple sentences per author: 10\n",
      "Maximum multiple sentences per author: 28\n",
      "Mean multiple sentences per author: 14.90\n"
     ]
    }
   ],
   "source": [
    "sentence_counts = gptset['Response'].apply(count_sentences)\n",
    "\n",
    "# Calculate statistics\n",
    "single_sentence = sum(sentence_counts == 1)\n",
    "multiple_sentences = sum(sentence_counts > 1)\n",
    "total_texts = len(sentence_counts)\n",
    "\n",
    "print(\"\\nChatGPT Summary:\")\n",
    "print(f\"Total texts: {total_texts}\")\n",
    "print(f\"Total single sentences: {single_sentence}\")\n",
    "print(f\"Total multiple sentences: {multiple_sentences}\")\n",
    "print(f\"Minimum multiple sentences per author: {author_stats['multiple_sentences'].min()}\")\n",
    "print(f\"Maximum multiple sentences per author: {author_stats['multiple_sentences'].max()}\")\n",
    "mean_multiple_sentences = author_stats['multiple_sentences'].mean()\n",
    "print(f\"Mean multiple sentences per author: {mean_multiple_sentences:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9e2b71b",
   "metadata": {},
   "source": [
    "# Load Dataset for Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5ba72dde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total student text: 327\n",
      "Total ChatGPT text: 273\n"
     ]
    }
   ],
   "source": [
    "#load dataset\n",
    "std_txt = []\n",
    "gpt_txt = []\n",
    "\n",
    "# Process Student essay\n",
    "for text in stdset['teks_esai']:\n",
    "    processed = preprocess_text(text)\n",
    "    if processed:\n",
    "        std_txt.append(processed)\n",
    "\n",
    "# Process ChatGPT essay\n",
    "for text in gptset['Response']:\n",
    "    processed = preprocess_text(text)\n",
    "    if processed:\n",
    "        gpt_txt.append(processed)\n",
    "\n",
    "\n",
    "# Show total number of processed texts\n",
    "print(f\"Total student text: {len(std_txt)}\")\n",
    "print(f\"Total ChatGPT text: {len(gpt_txt)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20bfcf3c",
   "metadata": {},
   "source": [
    "# Initialize BERT Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f04500e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize IndoBERT tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained(\"indobenchmark/indobert-base-p2\")\n",
    "\n",
    "# Tokenize function\n",
    "def tokenize_text(texts, max_length=256):\n",
    "    \"\"\"\n",
    "    Text tokenization using IndoBERT tokenizer.\n",
    "    \n",
    "    Args:\n",
    "        texts (list): List of texts to be tokenized.\n",
    "        max_length (int): Maximum token length.\n",
    "        \n",
    "    Returns:\n",
    "        dict: Tokenized result, including input_ids and attention_mask.\n",
    "    \"\"\"\n",
    "    return tokenizer(\n",
    "        texts,\n",
    "        padding='max_length',\n",
    "        truncation=True,\n",
    "        max_length=max_length,\n",
    "        return_tensors=\"tf\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8dcdc5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize student and ChatGPT essays\n",
    "print(\"Tokenize student essay...\")\n",
    "std_tokens = tokenize_text(std_txt)\n",
    "\n",
    "print(\"Tokenize ChatGPT essay...\")\n",
    "gpt_tokens = tokenize_text(gpt_txt)\n",
    "\n",
    "# Display tokenization results (example: Student)\n",
    "print(\"\\nExample of tokenization results:\")\n",
    "print(std_tokens['input_ids'][:3])  # Input token ID\n",
    "print(std_tokens['attention_mask'][:3])  # Attention mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2da4bfc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "student_lengths = [sum(mask) for mask in std_tokens['attention_mask'].numpy()]\n",
    "chatgpt_lengths = [sum(mask) for mask in gpt_tokens['attention_mask'].numpy()]\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(student_lengths, bins=30, alpha=0.5, label='Student', color='purple')\n",
    "plt.hist(chatgpt_lengths, bins=30, alpha=0.5, label='ChatGPT', color='orange')\n",
    "plt.title('Distribution of Token Lengths')\n",
    "plt.xlabel('Active Token Count')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()\n",
    "print(f\"Average token length for Student: {np.mean(student_lengths):.2f}\")\n",
    "print(f\"Percentage truncated for Student: {sum(l == 256 for l in student_lengths) / len(student_lengths) * 100:.2f}%\")\n",
    "print(f\"Average token length for ChatGPT: {np.mean(chatgpt_lengths):.2f}\")\n",
    "print(f\"Percentage truncated for ChatGPT: {sum(l == 256 for l in chatgpt_lengths) / len(chatgpt_lengths) * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0896a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decoding tokens for ensuring correctness\n",
    "sample_text = gpt_txt[0]\n",
    "sample_tokens = tokenizer.encode(sample_text)\n",
    "print(f\"Teks asli: {sample_text}\")\n",
    "print(f\"Token ID: {sample_tokens}\")\n",
    "print(f\"Token dekode: {tokenizer.decode(sample_tokens)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee363614",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save tokenized data\n",
    "tokenized_data = {\n",
    "    'student': std_tokens,\n",
    "    'chatgpt': gpt_tokens\n",
    "}\n",
    "\n",
    "# Save input_ids and attention_mask as numpy arrays\n",
    "tokenized_numpy = {\n",
    "    'student': {\n",
    "        'input_ids': std_tokens['input_ids'].numpy(),\n",
    "        'attention_mask': std_tokens['attention_mask'].numpy()\n",
    "    },\n",
    "    'chatgpt ': {\n",
    "        'input_ids': gpt_tokens ['input_ids'].numpy(),\n",
    "        'attention_mask': gpt_tokens ['attention_mask'].numpy()\n",
    "    }\n",
    "}\n",
    "\n",
    "os.makedirs(\"paper\", exist_ok=True)\n",
    "\n",
    "with open('paper/tokenized_data.pkl', 'wb') as f:\n",
    "    pickle.dump(tokenized_numpy, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a26faf74",
   "metadata": {},
   "source": [
    "# Build IndoBERT Semantic Similarity Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88f19b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load IndoBERT model\n",
    "bert_model = TFBertModel.from_pretrained(\"indobenchmark/indobert-base-p2\")\n",
    "\n",
    "# Freeze BERT layers\n",
    "for layer in bert_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Define Bi-Encoder model\n",
    "def model(bert_model):\n",
    "    \"\"\"\n",
    "    Create a Bi-Encoder model with IndoBERT.\n",
    "    \n",
    "    Args:\n",
    "        bert_model (TFBertModel): Base model of IndoBERT.\n",
    "        \n",
    "    Returns:\n",
    "        tf.keras.Model: Bi-Encoder model.\n",
    "    \"\"\"\n",
    "    # Input layer\n",
    "    input_ids = tf.keras.layers.Input(shape=(256,), dtype=tf.int32, name=\"input_ids\")\n",
    "    attention_mask = tf.keras.layers.Input(shape=(256,), dtype=tf.int32, name=\"attention_mask\")\n",
    "    \n",
    "    # Extract CLS token embeddings from IndoBERT\n",
    "    bert_output = bert_model(input_ids, attention_mask=attention_mask)[0][:, 0, :]  # [CLS] token\n",
    "    \n",
    "    # Dense layer for fine-tuning\n",
    "    dense1 = tf.keras.layers.Dense(256, activation=\"relu\")(bert_output)\n",
    "    dropout1 = tf.keras.layers.Dropout(0.1)(dense1)\n",
    "    dense2 = tf.keras.layers.Dense(256, activation=\"relu\")(dropout1)\n",
    "    dropout2 = tf.keras.layers.Dropout(0.1)(dense2)\n",
    "    dense3 = tf.keras.layers.Dense(256)(dropout2)\n",
    "    \n",
    "    # Output normalization (L2 normalization)\n",
    "    normalized_output = tf.nn.l2_normalize(dense3, axis=1)\n",
    "    \n",
    "    # Semantic model\n",
    "    return tf.keras.Model(inputs=[input_ids, attention_mask], outputs=normalized_output)\n",
    "\n",
    "# Build model\n",
    "semantic_model = model(bert_model)\n",
    "\n",
    "# Show model summary\n",
    "print(\"Model Summary:\")\n",
    "semantic_model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6cbf4d6",
   "metadata": {},
   "source": [
    "# Create Contrastive Pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fbc8883",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_contrastive_pairs(student_tokens, chatgpt_tokens, max_pairs=None):\n",
    "    \"\"\"\n",
    "    Creates data pairs for contrastive learning with dataset-appropriate quantities.\n",
    "\n",
    "    Args:\n",
    "        student_tokens: Tokenized student text\n",
    "        chatgpt_tokens_1: First set of tokenized ChatGPT text\n",
    "        chatgpt_tokens_2: Second set of tokenized ChatGPT text\n",
    "        max_pairs: Maximum number of pairs (optional). If None, uses all possible combinations.\n",
    "\n",
    "    Returns:\n",
    "        tuple: Dictionary of anchor, positive, negative pairs and labels, and the total number of pairs.\n",
    "    \"\"\"\n",
    "    # Get dataset sizes\n",
    "    n_student = student_tokens['input_ids'].shape[0]\n",
    "    n_chatgpt = chatgpt_tokens['input_ids'].shape[0]\n",
    "    \n",
    "    # Calculate maximum possible combinations\n",
    "    max_student_pairs = (n_student * (n_student - 1)) // 2  # student-student combinations\n",
    "    max_chatgpt_pairs = (n_chatgpt * (n_chatgpt - 1)) // 2  # chatgpt-chatgpt combinations\n",
    "    max_negative_pairs = n_student * n_chatgpt  # student-chatgpt combinations\n",
    "    \n",
    "    # Determine number of pairs to create\n",
    "    if max_pairs is None:\n",
    "        # Use minimum number of positive pairs for balance\n",
    "        n_pos_student = min(max_student_pairs, max_chatgpt_pairs) // 2\n",
    "        n_pos_chatgpt = n_pos_student\n",
    "        # Limit negative pairs to balance with positives\n",
    "        n_neg_pairs = min(max_negative_pairs, 2 * n_pos_student)\n",
    "    else:\n",
    "        # If max_pairs is specified, use that with equal proportions\n",
    "        n_pos_student = max_pairs // 4\n",
    "        n_pos_chatgpt = max_pairs // 4\n",
    "        n_neg_pairs = max_pairs // 2\n",
    "    \n",
    "    # Ensure we don't exceed the maximum possible combinations\n",
    "    n_pos_student = min(n_pos_student, max_student_pairs)\n",
    "    n_pos_chatgpt = min(n_pos_chatgpt, max_chatgpt_pairs)\n",
    "    n_neg_pairs = min(n_neg_pairs, max_negative_pairs)\n",
    "    \n",
    "    # Initialize arrays for data pairs\n",
    "    anchor_input_ids = []\n",
    "    anchor_attention_mask = []\n",
    "    positive_input_ids = []\n",
    "    positive_attention_mask = []\n",
    "    negative_input_ids = []\n",
    "    negative_attention_mask = []\n",
    "    labels = []\n",
    "    \n",
    "    # Generate positive student-student pairs\n",
    "    if n_pos_student > 0:\n",
    "        # Create all possible student-student pairs\n",
    "        student_pairs = [(i, j) for i in range(n_student) for j in range(i+1, n_student)]\n",
    "        # Randomly select pairs\n",
    "        selected_pairs = random.sample(student_pairs, n_pos_student)\n",
    "        \n",
    "        for idx1, idx2 in selected_pairs:\n",
    "            # Anchor (student)\n",
    "            anchor_input_ids.append(student_tokens['input_ids'][idx1])\n",
    "            anchor_attention_mask.append(student_tokens['attention_mask'][idx1])\n",
    "            \n",
    "            # Positive (another student)\n",
    "            positive_input_ids.append(student_tokens['input_ids'][idx2])\n",
    "            positive_attention_mask.append(student_tokens['attention_mask'][idx2])\n",
    "            \n",
    "            # Negative (from ChatGPT)\n",
    "            neg_idx = np.random.choice(n_chatgpt)\n",
    "            negative_input_ids.append(chatgpt_tokens['input_ids'][neg_idx])\n",
    "            negative_attention_mask.append(chatgpt_tokens['attention_mask'][neg_idx])\n",
    "            \n",
    "            # Label (1 for positive pair)\n",
    "            labels.append(1)\n",
    "    \n",
    "    # Generate positive chatgpt-chatgpt pairs\n",
    "    if n_pos_chatgpt > 0:\n",
    "        # Create all possible chatgpt-chatgpt pairs\n",
    "        chatgpt_pairs = [(i, j) for i in range(n_chatgpt) for j in range(i+1, n_chatgpt)]\n",
    "        # Randomly select pairs\n",
    "        selected_pairs = random.sample(chatgpt_pairs, n_pos_chatgpt)\n",
    "        \n",
    "        for idx1, idx2 in selected_pairs:\n",
    "            # Anchor\n",
    "            anchor_input_ids.append(chatgpt_tokens['input_ids'][idx1])\n",
    "            anchor_attention_mask.append(chatgpt_tokens['attention_mask'][idx1])\n",
    "            \n",
    "            # Positive\n",
    "            positive_input_ids.append(chatgpt_tokens['input_ids'][idx2])\n",
    "            positive_attention_mask.append(chatgpt_tokens['attention_mask'][idx2])\n",
    "            \n",
    "            # Negative (from Student)\n",
    "            neg_idx = np.random.choice(n_student)\n",
    "            negative_input_ids.append(student_tokens['input_ids'][neg_idx])\n",
    "            negative_attention_mask.append(student_tokens['attention_mask'][neg_idx])\n",
    "            \n",
    "            # Label (1 for positive pair)\n",
    "            labels.append(1)\n",
    "    \n",
    "    # Generate negative student-chatgpt pairs\n",
    "    if n_neg_pairs > 0:\n",
    "        # Create all possible student-chatgpt pairs\n",
    "        negative_pairs = [(i, j) for i in range(n_student) for j in range(n_chatgpt)]\n",
    "        # Randomly select pairs\n",
    "        selected_pairs = random.sample(negative_pairs, n_neg_pairs)\n",
    "        \n",
    "        for student_idx, chatgpt_idx in selected_pairs:\n",
    "            # Anchor (Student)\n",
    "            anchor_input_ids.append(student_tokens['input_ids'][student_idx])\n",
    "            anchor_attention_mask.append(student_tokens['attention_mask'][student_idx])\n",
    "            \n",
    "            # Negative (ChatGPT)\n",
    "            negative_input_ids.append(chatgpt_tokens['input_ids'][chatgpt_idx])\n",
    "            negative_attention_mask.append(chatgpt_tokens['attention_mask'][chatgpt_idx])\n",
    "            \n",
    "            # Positive (another Student different from anchor)\n",
    "            available_pos = [i for i in range(n_student) if i != student_idx]\n",
    "            if available_pos:  # Ensure there are available indices\n",
    "                pos_idx = np.random.choice(available_pos)\n",
    "                positive_input_ids.append(student_tokens['input_ids'][pos_idx])\n",
    "                positive_attention_mask.append(student_tokens['attention_mask'][pos_idx])\n",
    "                \n",
    "                # Label (0 for negative pair)\n",
    "                labels.append(0)\n",
    "    \n",
    "    # Count actual pairs created\n",
    "    actual_pairs = len(labels)\n",
    "    \n",
    "    # Convert to tensors and return\n",
    "    return {\n",
    "        'anchor': {\n",
    "            'input_ids': tf.convert_to_tensor(anchor_input_ids, dtype=tf.int32),\n",
    "            'attention_mask': tf.convert_to_tensor(anchor_attention_mask, dtype=tf.int32)\n",
    "        },\n",
    "        'positive': {\n",
    "            'input_ids': tf.convert_to_tensor(positive_input_ids, dtype=tf.int32),\n",
    "            'attention_mask': tf.convert_to_tensor(positive_attention_mask, dtype=tf.int32)\n",
    "        },\n",
    "        'negative': {\n",
    "            'input_ids': tf.convert_to_tensor(negative_input_ids, dtype=tf.int32),\n",
    "            'attention_mask': tf.convert_to_tensor(negative_attention_mask, dtype=tf.int32)\n",
    "        },\n",
    "        'labels': tf.convert_to_tensor(labels, dtype=tf.float32)\n",
    "    }, actual_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d36a243",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create contrastive pairs\n",
    "student_chatgpt_pairs, total_pairs = create_contrastive_pairs(std_tokens, gpt_tokens, max_pairs=None)\n",
    "\n",
    "# Show the number of pairs created\n",
    "print(f\"Total contrastive pairs yang dibuat: {total_pairs}\")\n",
    "print(f\"- Pasangan positif student-student: {sum(1 for label in student_chatgpt_pairs['labels'].numpy() if label == 1)//2}\")\n",
    "print(f\"- Pasangan positif chatgpt-chatgpt: {sum(1 for label in student_chatgpt_pairs['labels'].numpy() if label == 1)//2}\")\n",
    "print(f\"- Pasangan negatif student-chatgpt: {sum(1 for label in student_chatgpt_pairs['labels'].numpy() if label == 0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b7571a6",
   "metadata": {},
   "source": [
    "# Build Triplet Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abc30b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model for training with triplet loss\n",
    "def triplet_model(semantic_model):\n",
    "    \"\"\"\n",
    "    Build a model for training with triplet loss.\n",
    "    \n",
    "    Args:\n",
    "        semantic_model: The semantic similarity model to be trained.\n",
    "        \n",
    "    Returns:\n",
    "         tf.keras.Model: Model for training with triplet loss.\n",
    "    \"\"\"\n",
    "    # Input for anchor, positive, and negative\n",
    "    anchor_input_ids = tf.keras.layers.Input(shape=(256,), dtype=tf.int32, name=\"anchor_input_ids\")\n",
    "    anchor_attention_mask = tf.keras.layers.Input(shape=(256,), dtype=tf.int32, name=\"anchor_attention_mask\")\n",
    "    \n",
    "    positive_input_ids = tf.keras.layers.Input(shape=(256,), dtype=tf.int32, name=\"positive_input_ids\")\n",
    "    positive_attention_mask = tf.keras.layers.Input(shape=(256,), dtype=tf.int32, name=\"positive_attention_mask\")\n",
    "    \n",
    "    negative_input_ids = tf.keras.layers.Input(shape=(256,), dtype=tf.int32, name=\"negative_input_ids\")\n",
    "    negative_attention_mask = tf.keras.layers.Input(shape=(256,), dtype=tf.int32, name=\"negative_attention_mask\")\n",
    "    \n",
    "    # Embedding for anchor, positive, and negative\n",
    "    anchor_embedding = semantic_model([anchor_input_ids, anchor_attention_mask])\n",
    "    positive_embedding = semantic_model([positive_input_ids, positive_attention_mask])\n",
    "    negative_embedding = semantic_model([negative_input_ids, negative_attention_mask])\n",
    "    \n",
    "    # measure cosine similarity\n",
    "    pos_similarity = tf.reduce_sum(anchor_embedding * positive_embedding, axis=1)\n",
    "    neg_similarity = tf.reduce_sum(anchor_embedding * negative_embedding, axis=1)\n",
    "    \n",
    "    # Model output is the similarity score\n",
    "    output = tf.stack([pos_similarity, neg_similarity], axis=1)\n",
    "    \n",
    "    return tf.keras.Model(\n",
    "        inputs=[\n",
    "            anchor_input_ids, anchor_attention_mask,\n",
    "            positive_input_ids, positive_attention_mask,\n",
    "            negative_input_ids, negative_attention_mask\n",
    "        ],\n",
    "        outputs=output\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5659fd85",
   "metadata": {},
   "source": [
    "# Create Triplet Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32fa9d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Triplet loss function\n",
    "def triplet_loss(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Triplet loss: tunes the network such that\n",
    "the distance between a and p is smaller than the\n",
    "distance between a and n.\n",
    "    \n",
    "    Args:\n",
    "        y_true: not used triplet loss.\n",
    "        y_pred: stack of [positive_similarity, negative_similarity].\n",
    "        \n",
    "    Returns:\n",
    "        tf.Tensor: loss value.\n",
    "    \"\"\"\n",
    "    pos_sim = y_pred[:, 0]\n",
    "    neg_sim = y_pred[:, 1]\n",
    "    margin = 0.5\n",
    "    \n",
    "    # Triplet loss: max(0, margin - (pos_sim - neg_sim))\n",
    "    loss = tf.maximum(0., margin - (pos_sim - neg_sim))\n",
    "    return tf.reduce_mean(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdb09fe5",
   "metadata": {},
   "source": [
    "# Train The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f3a84cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build triplet model for student vs ChatGPT essay\n",
    "build_triplet = triplet_model(semantic_model)\n",
    "\n",
    "# Compile model\n",
    "build_triplet.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=2e-5),\n",
    "    loss=triplet_loss\n",
    ")\n",
    "\n",
    "# Training model Student_ChatGPT\n",
    "print(\"Training model...\")\n",
    "history = build_triplet.fit(\n",
    "    x=[\n",
    "        student_chatgpt_pairs['anchor']['input_ids'],\n",
    "        student_chatgpt_pairs['anchor']['attention_mask'],\n",
    "        student_chatgpt_pairs['positive']['input_ids'],\n",
    "        student_chatgpt_pairs['positive']['attention_mask'],\n",
    "        student_chatgpt_pairs['negative']['input_ids'],\n",
    "        student_chatgpt_pairs['negative']['attention_mask']\n",
    "    ],\n",
    "    y=student_chatgpt_pairs['labels'],  # not used in triplet loss\n",
    "    epochs=10,\n",
    "    batch_size=32,\n",
    "    validation_split=0.2,\n",
    "    callbacks=[\n",
    "        tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=2, restore_best_weights=True)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8a46e7b",
   "metadata": {},
   "source": [
    "# Training History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1e3eb19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training history untuk model Student_ChatGPT\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Model Student_ChatGPT: Training and Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2265bd25",
   "metadata": {},
   "source": [
    "# Generate Embeddings Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c6ae85c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_emb(tokens, model):\n",
    "    \"\"\"\n",
    "    Generate embeddings using IndoBERT.\n",
    "    \n",
    "    Args:\n",
    "        tokens: Token from text.\n",
    "        model: IndoBERT Semantic Similarity.\n",
    "        \n",
    "    Returns:\n",
    "        tf.Tensor: Embeddings.\n",
    "    \"\"\"\n",
    "    return model([tokens['input_ids'], tokens['attention_mask']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1bee85e",
   "metadata": {},
   "source": [
    "# Cosine Similarity Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "048d0402",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cos_sim(embedding1, embedding2):\n",
    "    \"\"\"\n",
    "    Calculate similarity score using standard cosine similarity.\n",
    "    \n",
    "    Args:\n",
    "        embedding1: First embedding (input text)\n",
    "        embedding2: Second embedding (reference)\n",
    "        \n",
    "    Returns:\n",
    "        float: Average cosine similarity score\n",
    "    \"\"\"\n",
    "    # Normalize embeddings (L2 norm)\n",
    "    embedding1_norm = tf.nn.l2_normalize(embedding1, axis=-1)\n",
    "    embedding2_norm = tf.nn.l2_normalize(embedding2, axis=-1)\n",
    "    \n",
    "    # Calculate cosine similarity\n",
    "    similarity = tf.reduce_sum(embedding1_norm * embedding2_norm)\n",
    "    \n",
    "    return similarity.numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aae74ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('paper'):\n",
    "    os.makedirs('paper')\n",
    "\n",
    "history.save('paper/semantic_model.h5')\n",
    "\n",
    "# Save tokenizer configuration\n",
    "tokenizer.save_pretrained('paper/tokenizer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa48304c",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_objects = {'TFBertModel': TFBertModel}\n",
    "\n",
    "with tf.keras.utils.custom_object_scope(custom_objects):\n",
    "    semantic_model = tf.keras.models.load_model('paper/semantic_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e94ca615",
   "metadata": {},
   "source": [
    "# Generate Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "234dea03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate embeddings untuk semua data\n",
    "print(\"Generating embeddings for Student...\")\n",
    "std_emb = gen_emb(std_tokens, semantic_model)\n",
    "print(\"Generating embeddings for ChatGPT...\")\n",
    "gpt_emb = gen_emb(gpt_tokens, semantic_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25a78f7e",
   "metadata": {},
   "source": [
    "# Measure Similarity Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "926b4188",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Similarity dengan Student (dari model Student_ChatGPT)\n",
    "std_std_sim_scores = []\n",
    "std_gpt_sim_scores = []\n",
    "for emb in std_emb:\n",
    "    avg_similarity = cos_sim(tf.expand_dims(emb, 0), std_emb)\n",
    "    std_std_sim_scores.append(avg_similarity)\n",
    "\n",
    "    avg_similarity = cos_sim(tf.expand_dims(emb, 0), gpt_emb)\n",
    "    std_gpt_sim_scores.append(avg_similarity)\n",
    "\n",
    "# 2. Similarity dengan ChatGPT (dari model Student_ChatGPT)\n",
    "gpt_std_sim_scores = []\n",
    "gpt_gpt_sim_scores = []\n",
    "for emb in gpt_emb:\n",
    "    avg_similarity = cos_sim(tf.expand_dims(emb, 0), std_emb)\n",
    "    gpt_std_sim_scores.append(avg_similarity)\n",
    "\n",
    "    avg_similarity = cos_sim(tf.expand_dims(emb, 0), gpt_emb)\n",
    "    gpt_gpt_sim_scores.append(avg_similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87a87f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_length = min(len(std_std_sim_scores), len(std_gpt_sim_scores))\n",
    "student_similarity_scores = np.array([\n",
    "    std_std_sim_scores[:min_length], \n",
    "    std_gpt_sim_scores[:min_length],\n",
    "])\n",
    "\n",
    "min_length = min(len(gpt_std_sim_scores), len(gpt_gpt_sim_scores))\n",
    "chatgpt_similarity_scores = np.array([\n",
    "    gpt_std_sim_scores[:min_length], \n",
    "    gpt_gpt_sim_scores[:min_length],\n",
    "])\n",
    "\n",
    "print(student_similarity_scores.shape)\n",
    "print(chatgpt_similarity_scores.shape)\n",
    "\n",
    "ref_emb = {\n",
    "    'student': {\n",
    "        'embeddings': std_emb.numpy(),\n",
    "        'similarity_scores': student_similarity_scores\n",
    "    },\n",
    "    'chatgpt': {\n",
    "        'embeddings': gpt_emb.numpy(),\n",
    "        'similarity_scores': chatgpt_similarity_scores\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ea813fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_pairs = []\n",
    "pd.set_option('display.max_colwidth', None)  \n",
    "pd.set_option('display.width', 1000)        \n",
    "pd.set_option('display.max_rows', None)      \n",
    "\n",
    "for i, student_text in enumerate(std_txt):\n",
    "    if i >= len(std_emb):\n",
    "        continue\n",
    "        \n",
    "    student_embedding = tf.expand_dims(std_emb[i], 0)\n",
    "\n",
    "    for j in range(len(gpt_txt)):\n",
    "        if j >= len(gpt_emb):\n",
    "            continue\n",
    "\n",
    "        chatgpt_embedding = tf.expand_dims(gpt_emb[j], 0)\n",
    "        similarity = cos_sim(student_embedding, chatgpt_embedding)\n",
    "        \n",
    "        all_pairs.append({\n",
    "            'student_idx': i,\n",
    "            'chatgpt_idx': j,\n",
    "            'student_text': student_text,\n",
    "            'chatgpt_text': gpt_txt[j],\n",
    "            'similarity_score': similarity\n",
    "        })\n",
    "\n",
    "sorted_pairs = sorted(all_pairs, key=lambda x: x['similarity_score'], reverse=True)\n",
    "\n",
    "result_v1 = sorted_pairs[:5]\n",
    "\n",
    "df_v1 = pd.DataFrame(result_v1)[['student_text', 'chatgpt_text', 'similarity_score']]\n",
    "df_v1.columns = ['Student Essay', 'ChatGPT Essay', 'Similarity Score']\n",
    "\n",
    "print(\"=== 1: Standard ===\")\n",
    "display(df_v1)\n",
    "\n",
    "used_student_indices_v2 = set()\n",
    "used_chatgpt_indices_v2 = set()\n",
    "result_v2 = []\n",
    "\n",
    "for pair in sorted_pairs:\n",
    "    if (pair['student_idx'] in used_student_indices_v2 or \n",
    "        pair['chatgpt_idx'] in used_chatgpt_indices_v2):\n",
    "        continue\n",
    "    result_v2.append(pair)\n",
    "    used_student_indices_v2.add(pair['student_idx'])\n",
    "    used_chatgpt_indices_v2.add(pair['chatgpt_idx'])\n",
    "    if len(result_v2) >= 5:\n",
    "        break\n",
    "\n",
    "df_v2 = pd.DataFrame(result_v2)[['student_text', 'chatgpt_text', 'similarity_score']]\n",
    "df_v2.columns = ['Student Essay', 'ChatGPT Essay', 'Similarity Score']\n",
    "\n",
    "print(\"=== 2: Unique ===\")\n",
    "display(df_v2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "180d3c91",
   "metadata": {},
   "source": [
    "# Visualization of Similarity Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebe10ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 6))\n",
    "\n",
    "student_student_color = \"#9747FF\"  \n",
    "student_chatgpt_color = \"#FCD19C\"  \n",
    "chatgpt_chatgpt_color = \"#FFA629\"  \n",
    "chatgpt_student_color = \"#E4CCFF\"  \n",
    "\n",
    "# Subplot 1: Student\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.scatter(range(len(std_std_sim_scores)), std_std_sim_scores, \n",
    "            label='Student-Student', color=student_student_color, s=70, alpha=0.8, edgecolor='black', linewidth=0.5)\n",
    "plt.scatter(range(len(std_gpt_sim_scores)), std_gpt_sim_scores, \n",
    "            label='Student-ChatGPT', color=student_chatgpt_color, s=70, alpha=0.8, edgecolor='black', linewidth=0.5)\n",
    "plt.title('Student Essay', fontsize=14, fontweight='bold')\n",
    "plt.ylim(-1.05, 1.05)  \n",
    "plt.yticks(np.arange(-1, 1.1, 0.1))\n",
    "plt.legend(fontsize=10)\n",
    "plt.grid(True, linestyle='--', alpha=0.3)\n",
    "\n",
    "# Subplot 2: ChatGPT\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.scatter(range(len(gpt_std_sim_scores)), gpt_std_sim_scores, \n",
    "            label='ChatGPT-Student', color=chatgpt_student_color, s=70, alpha=0.8, edgecolor='black', linewidth=0.5)\n",
    "plt.scatter(range(len(gpt_gpt_sim_scores)), gpt_gpt_sim_scores, \n",
    "            label='ChatGPT-ChatGPT', color=chatgpt_chatgpt_color, s=70, alpha=0.8, edgecolor='black', linewidth=0.5)\n",
    "plt.title('ChatGPT Essay', fontsize=14, fontweight='bold')\n",
    "plt.ylim(-1.05, 1.05)  \n",
    "plt.yticks(np.arange(-1, 1.1, 0.1))\n",
    "plt.legend(fontsize=10)\n",
    "plt.grid(True, linestyle='--', alpha=0.3)\n",
    "\n",
    "plt.suptitle('Similarity Scores Comparison', fontsize=16, fontweight='bold', y=0.98)\n",
    "plt.tight_layout()\n",
    "plt.subplots_adjust(top=0.85)  \n",
    "\n",
    "os.makedirs('paper/images', exist_ok=True)\n",
    "plt.savefig('paper/images/similarity_scores_comparison.png', dpi=300, bbox_inches='tight')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f323713e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('paper/reference_embeddings_1.pkl', 'wb') as f:\n",
    "    pickle.dump(ref_emb, f)\n",
    "\n",
    "print(\"Reference embeddings saved successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "564ab90c",
   "metadata": {},
   "source": [
    "# Define Linguistic Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7408bf6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def linguistic_features(text):\n",
    "    \"\"\"\n",
    "    Features extraction from text:\n",
    "    1.\tLexical Diversity\n",
    "    2.\tTotal words in the essay\n",
    "    3.\tTotal unique words*\n",
    "    4.\tModals\n",
    "    5.\tStopwords ratio*\n",
    "    6.\tAverage sentence length*\n",
    "    7.\tSentence length variation*\n",
    "    8.\tPunctuation Ratio*\n",
    "\n",
    "    \n",
    "    Args:\n",
    "        text (str): Input text.\n",
    "        \n",
    "    Returns:\n",
    "        dict: Linguistic features.\n",
    "    \"\"\"\n",
    "    words = re.findall(r'\\b\\w+\\b', text)\n",
    "    sentences = re.split(r'[.!?]', text)\n",
    "    sentences = [s.strip() for s in sentences if s.strip()]\n",
    "\n",
    "    word_count = len(words)\n",
    "    unique_count = len(set(words))\n",
    "    \n",
    "    ld = (unique_count / word_count * 100) if word_count > 0 else 0\n",
    "    \n",
    "    # Load modals from corpus file\n",
    "    modals = set()\n",
    "    if os.path.exists('corpus/Indonesian_Manually_Tagged_Corpus_ID.tsv'):\n",
    "        with open('corpus/Indonesian_Manually_Tagged_Corpus_ID.tsv', 'r', encoding='utf-8') as f:\n",
    "            for line in f:\n",
    "                if line.strip():\n",
    "                    parts = line.strip().split('\\t')\n",
    "                    if len(parts) >= 2 and parts[1] == 'MD':\n",
    "                        modals.add(parts[0].lower())\n",
    "    \n",
    "    # Count modals in text\n",
    "    modal_count = sum(1 for word in words if word.lower() in modals)\n",
    "    \n",
    "    # Load stopwords from file\n",
    "    stopwords = set()\n",
    "    if os.path.exists('corpus/stopwords.txt'):\n",
    "        with open('corpus/stopwords.txt', 'r', encoding='utf-8') as f:\n",
    "            for line in f:\n",
    "                stopwords.add(line.strip())\n",
    "    \n",
    "    # Calculate stopword ratio\n",
    "    stopword_count = sum(1 for word in words if word.lower() in stopwords)\n",
    "    stopword_ratio = (stopword_count / word_count * 100) if word_count > 0 else 0\n",
    "    \n",
    "    # Calculate sentence length statistics\n",
    "    sentence_lengths = [len(re.findall(r'\\b\\w+\\b', s)) for s in sentences]\n",
    "    avg_sent_len = np.mean(sentence_lengths) if sentence_lengths else 0\n",
    "    sent_len_var = np.std(sentence_lengths) if len(sentence_lengths) > 1 else 0\n",
    "    \n",
    "    # Calculate punctuation ratio\n",
    "    punct_count = len(re.findall(r'[.!?]', text))\n",
    "    punct_ratio = (punct_count / word_count) * 100 if word_count > 0 else 0\n",
    "\n",
    "    return {\n",
    "        'lexical_diversity': ld,\n",
    "        'total_words': word_count,\n",
    "        'total_unique_words': unique_count,\n",
    "        'modals': modal_count,\n",
    "        'stopwords_ratio': stopword_ratio,\n",
    "        'avg_sentence_length': avg_sent_len,\n",
    "        'sentence_length_variation': sent_len_var,\n",
    "        'punctuation_ratio': punct_ratio\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dbb7a06",
   "metadata": {},
   "source": [
    "# Features Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f72b33be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature extraction for Student and ChatGPT essays\n",
    "print(\"Features extraction for Student...\")\n",
    "std_features = [linguistic_features(text) for text in std_txt]\n",
    "\n",
    "print(\"Features extraction for ChatGPT...\")\n",
    "gpt_features = [linguistic_features(text) for text in gpt_txt]\n",
    "\n",
    "\n",
    "# convert\n",
    "std_features_df = pd.DataFrame(std_features)\n",
    "gpt_features_df = pd.DataFrame(gpt_features)\n",
    "\n",
    "\n",
    "# Tampilkan beberapa fitur hasil ekstraksi\n",
    "print(\"\\nStudent Linguistic Features:\")\n",
    "display(std_features_df.head())\n",
    "\n",
    "print(\"\\nChatGPT Linguistic Features:\")\n",
    "display(gpt_features_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46f2ccff",
   "metadata": {},
   "source": [
    "# Normalize Linguistic Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2425049c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine features into a single DataFrame\n",
    "all_features = pd.concat([std_features_df, gpt_features_df], axis=0)\n",
    "\n",
    "# Normalize features\n",
    "scaler = StandardScaler()\n",
    "normalized_features = scaler.fit_transform(all_features)\n",
    "\n",
    "# Separate normalized features back into student and ChatGPT\n",
    "n_student = len(std_features_df)\n",
    "n_chatgpt_1 = len(gpt_features_df)\n",
    "\n",
    "std_features_norm = normalized_features[:n_student]\n",
    "gpt_features_norm = normalized_features[n_student:n_student + n_chatgpt_1]\n",
    "\n",
    "print(\"Student features after normalization:\")\n",
    "print(std_features_norm[:5])\n",
    "\n",
    "print(\"ChatGPT features after normalization:\")\n",
    "print(gpt_features_norm[:5])\n",
    "\n",
    "# Save scaler for later inference\n",
    "try:\n",
    "    with open('paper/scaler_stylometric.pkl', 'wb') as f:\n",
    "        pickle.dump(scaler, f)\n",
    "    print(\"Scaler saved successfully.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error saving scaler: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87746ebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add labels to features\n",
    "std_features_df['label'] = 'Student Essay'\n",
    "gpt_features_df['label'] = 'ChatGPT Essay'\n",
    "\n",
    "# Combine datasets\n",
    "combined_features = pd.concat([std_features_df, gpt_features_df], axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe4e7238",
   "metadata": {},
   "source": [
    "# Visualize Linguistic Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6376d746",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 20))\n",
    "for i, feature in enumerate([\n",
    "    'lexical_diversity',\n",
    "    'total_words',\n",
    "    'total_unique_words',\n",
    "    'modals',\n",
    "    'stopwords_ratio',\n",
    "    'avg_sentence_length',\n",
    "    'sentence_length_variation',\n",
    "    'punctuation_ratio'\n",
    "]):\n",
    "    plt.subplot(3, 3, i+1)\n",
    "    sns.boxplot(x='label', y=feature, data=combined_features)\n",
    "    plt.title(f'Distribution {feature}')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "906067eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Student Similarity Score shape: {student_similarity_scores.shape}\")\n",
    "print(f\"ChatGPT Similarity Score shape: {chatgpt_similarity_scores.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90390e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine embeddings for model 1 (already correct)\n",
    "emb_features = np.vstack([std_emb.numpy(), gpt_emb.numpy()])\n",
    "\n",
    "student_features_selected = std_features_norm\n",
    "chatgpt_features_selected = gpt_features_norm\n",
    "\n",
    "all_linguistic_features = np.vstack([\n",
    "    student_features_selected,\n",
    "    chatgpt_features_selected\n",
    "])\n",
    "\n",
    "all_similarity_scores = np.vstack([\n",
    "    student_similarity_scores,\n",
    "    chatgpt_similarity_scores,\n",
    "])\n",
    "\n",
    "# Create labels\n",
    "student_labels = np.zeros(len(std_emb))  # Label 0 for Student\n",
    "chatgpt_labels = np.ones(len(gpt_emb))   # Label 1 for ChatGPT\n",
    "all_labels = np.hstack([student_labels, chatgpt_labels])\n",
    "\n",
    "# Verify shapes\n",
    "print(f\"embeddings_model shape: {emb_features.shape}\")\n",
    "print(f\"all_linguistic_features shape: {all_linguistic_features.shape}\")\n",
    "print(f\"all_similarity_scores shape: {all_similarity_scores.shape}\")\n",
    "print(f\"all_labels shape: {all_labels.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "973e31a6",
   "metadata": {},
   "source": [
    "# Build Classification Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7df763d",
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_input = tf.keras.layers.Input(\n",
    "    shape=(256,),\n",
    "    dtype=tf.float32, \n",
    "    name=\"bert_embedding_1\"\n",
    ")\n",
    "\n",
    "sim_score_input = tf.keras.layers.Input(\n",
    "    shape=(2,),  # Shape score similarity (Student, ChatGPT1, ChatGPT2)\n",
    "    dtype=tf.float32, \n",
    "    name=\"similarity_score\"\n",
    ")\n",
    "\n",
    "linguistic_input = tf.keras.layers.Input(\n",
    "    shape=(8,),\n",
    "    dtype=tf.float32, \n",
    "    name=\"stylometric_features\"\n",
    ")\n",
    "\n",
    "emb_dense = tf.keras.layers.Dense(256, activation=\"relu\")(emb_input)\n",
    "sim_dense = tf.keras.layers.Dense(16, activation=\"relu\")(sim_score_input)\n",
    "lin_dense = tf.keras.layers.Dense(64, activation=\"relu\")(linguistic_input)\n",
    "\n",
    "combined = tf.keras.layers.Concatenate()([emb_dense, sim_dense, lin_dense])\n",
    "\n",
    "x = tf.keras.layers.Dense(128, activation=\"relu\")(combined)\n",
    "x = tf.keras.layers.Dropout(0.2)(x)\n",
    "x = tf.keras.layers.Dense(64, activation=\"relu\")(x)\n",
    "output = tf.keras.layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "\n",
    "classifier = tf.keras.Model(\n",
    "    inputs=[emb_input, sim_score_input, linguistic_input],\n",
    "    outputs=output,\n",
    "    name=\"text_classifier\"\n",
    ")\n",
    "\n",
    "classifier.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n",
    "    loss=\"binary_crossentropy\",\n",
    "    metrics=[\"accuracy\", tf.keras.metrics.Precision(), tf.keras.metrics.Recall(), tf.keras.metrics.AUC()]\n",
    ")\n",
    "\n",
    "classifier.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e7b5c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = std_txt + gpt_txt\n",
    "labels = [0] * len(std_txt) + [1] * len(gpt_txt)  # 0 for student, 1 for ChatGPT\n",
    "data = pd.DataFrame({'text': texts, 'label': labels})\n",
    "\n",
    "train_data, test_data = train_test_split(\n",
    "    data, test_size=0.2, random_state=42, stratify=data['label']\n",
    ")\n",
    "\n",
    "print(f\"Initial training set: {len(train_data)} samples\")\n",
    "print(f\"Initial test set: {len(test_data)} samples\")\n",
    "print(f\"Initial training distribution: Student={sum(train_data['label']==0)}, ChatGPT={sum(train_data['label']==1)}\")\n",
    "\n",
    "\n",
    "X_train = train_data[['text']]\n",
    "y_train = train_data['label']\n",
    "\n",
    "undersampler = RandomUnderSampler(random_state=42)\n",
    "X_train_indices = pd.DataFrame({'index': range(len(X_train))})\n",
    "X_resampled_indices, y_resampled = undersampler.fit_resample(X_train_indices, y_train)\n",
    "\n",
    "selected_indices = X_resampled_indices['index'].values\n",
    "\n",
    "balanced_train_data = train_data.iloc[selected_indices].reset_index(drop=True)\n",
    "\n",
    "removed_indices = set(range(len(train_data))) - set(selected_indices)\n",
    "removed_samples = train_data.iloc[list(removed_indices)]\n",
    "\n",
    "test_set = pd.concat([test_data, removed_samples]).reset_index(drop=True)\n",
    "\n",
    "train_set, val_set = train_test_split(\n",
    "    balanced_train_data, test_size=0.05/0.80, random_state=42, stratify=balanced_train_data['label']\n",
    ")\n",
    "\n",
    "# Print final dataset statistics\n",
    "print(\"\\nAfter undersampling:\")\n",
    "print(f\"Training set: {len(train_set)} samples (Student={sum(train_set['label']==0)}, ChatGPT={sum(train_set['label']==1)})\")\n",
    "print(f\"Validation set: {len(val_set)} samples (Student={sum(val_set['label']==0)}, ChatGPT={sum(val_set['label']==1)})\")\n",
    "print(f\"Test set: {len(test_set)} samples (Student={sum(test_set['label']==0)}, ChatGPT={sum(test_set['label']==1)})\")\n",
    "\n",
    "\n",
    "# Prepare inputs for training, validation, and test\n",
    "train_inputs = {\n",
    "    \"embeddings_input\": emb_input[train_set],\n",
    "    \"similarity_score\": sim_score_input[train_set],\n",
    "    \"linguistic_features\": linguistic_input[train_set]\n",
    "}\n",
    "\n",
    "val_inputs = {\n",
    "    \"embeddings_input\": emb_input[val_set],\n",
    "    \"similarity_score\": sim_score_input[val_set],\n",
    "    \"linguistic_features\": linguistic_input[val_set]\n",
    "}\n",
    "\n",
    "\n",
    "test_inputs = {\n",
    "    \"embeddings_input\": emb_input[test_set],\n",
    "    \"similarity_score\": sim_score_input[test_set],\n",
    "    \"linguistic_features\": linguistic_input[test_set]\n",
    "}\n",
    "\n",
    "train_labels = all_labels[train_set]\n",
    "val_labels = all_labels[train_set]\n",
    "test_labels = all_labels[train_set]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95ab9e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training classifier\n",
    "print(\"Training Classification Model...\")\n",
    "history_classifier = classifier.fit(\n",
    "    train_inputs,\n",
    "    train_labels,\n",
    "    validation_data=(val_inputs, val_labels),\n",
    "    epochs=20,\n",
    "    batch_size=32,\n",
    "    callbacks=[\n",
    "        tf.keras.callbacks.EarlyStopping(\n",
    "            monitor='val_loss',\n",
    "            patience=3,\n",
    "            restore_best_weights=True\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Plot training history\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history_classifier.history['loss'], label='Training Loss')\n",
    "plt.plot(history_classifier.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Model Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history_classifier.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history_classifier.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title('Model Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "195ee82e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model evaluation\n",
    "print(\"Evaluating model on validation set...\")\n",
    "val_loss, val_acc, val_precision, val_recall, val_auc = classifier.evaluate(val_inputs, val_labels)\n",
    "print(f\"Validation Loss: {val_loss:.4f}\")\n",
    "print(f\"Validation Accuracy: {val_acc:.4f}\")\n",
    "print(f\"Validation Precision: {val_precision:.4f}\")\n",
    "print(f\"Validation Recall: {val_recall:.4f}\")\n",
    "print(f\"Validation AUC: {val_auc:.4f}\")\n",
    "\n",
    "# Predictions on validation set\n",
    "print(\"Making predictions on validation set...\")\n",
    "val_predictions = classifier.predict(val_inputs)\n",
    "val_predictions_binary = (val_predictions > 0.5).astype(int)\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(val_labels, val_predictions_binary)\n",
    "\n",
    "# Visualisasi confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Student', 'ChatGPT'], yticklabels=['Student', 'ChatGPT'])\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.show()\n",
    "\n",
    "# Classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(val_labels, val_predictions_binary, target_names=['Student', 'ChatGPT']))\n",
    "\n",
    "# Model evaluation on test set\n",
    "print(\"Evaluating model on test set...\")\n",
    "test_loss, test_acc, test_precision, test_recall, test_auc = classifier.evaluate(test_inputs, test_labels)\n",
    "print(f\"Test Loss: {test_loss:.4f}\")\n",
    "print(f\"Test Accuracy: {test_acc:.4f}\")\n",
    "print(f\"Test Precision: {test_precision:.4f}\")\n",
    "print(f\"Test Recall: {test_recall:.4f}\")\n",
    "print(f\"Test AUC: {test_auc:.4f}\")\n",
    "\n",
    "# Predictions on test set\n",
    "print(\"Making predictions on test set...\")\n",
    "test_predictions = classifier.predict(test_inputs)\n",
    "test_predictions_binary = (test_predictions > 0.5).astype(int)\n",
    "\n",
    "# Confusion matrix for test set\n",
    "cm_test = confusion_matrix(test_labels, test_predictions_binary)\n",
    "\n",
    "# Visualizing confusion matrix for test set\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm_test, annot=True, fmt='d', cmap='Blues', xticklabels=['Student', 'ChatGPT'], yticklabels=['Student', 'ChatGPT'])\n",
    "plt.title('Test Set Confusion Matrix')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.show()\n",
    "\n",
    "# Classification report for test set\n",
    "print(\"\\nTest Set Classification Report:\")\n",
    "print(classification_report(test_labels, test_predictions_binary, target_names=['Student', 'ChatGPT']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f627f555",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot ROC curve\n",
    "def plot_roc_curve(labels, predictions, title):\n",
    "    fpr, tpr, _ = roc_curve(labels, predictions)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    \n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc:.2f})')\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title(f'ROC Curve - {title}')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n",
    "    \n",
    "    return roc_auc\n",
    "\n",
    "# Plot ROC curve for validation set\n",
    "val_auc_score = plot_roc_curve(val_labels, val_predictions, \"Validation Set\")\n",
    "print(f\"Validation AUC from ROC curve: {val_auc_score:.4f}\")\n",
    "\n",
    "# Plot ROC curve for test set\n",
    "test_auc_score = plot_roc_curve(test_labels, test_predictions, \"Test Set\")\n",
    "print(f\"Test AUC from ROC curve: {test_auc_score:.4f}\")\n",
    "\n",
    "# Plot both ROC curves in one graph for comparison\n",
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "# Validation set\n",
    "fpr_val, tpr_val, _ = roc_curve(val_labels, val_predictions)\n",
    "roc_auc_val = auc(fpr_val, tpr_val)\n",
    "plt.plot(fpr_val, tpr_val, color='darkorange', lw=2, label=f'Validation ROC (area = {roc_auc_val:.2f})')\n",
    "\n",
    "# Test set\n",
    "fpr_test, tpr_test, _ = roc_curve(test_labels, test_predictions)\n",
    "roc_auc_test = auc(fpr_test, tpr_test)\n",
    "plt.plot(fpr_test, tpr_test, color='green', lw=2, label=f'Test ROC (area = {roc_auc_test:.2f})')\n",
    "\n",
    "# Diagonal line\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curves - Comparison')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43fe7285",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('paper'):\n",
    "    os.makedirs('paper')\n",
    "\n",
    "history.save('paper/semantic_model.h5')\n",
    "classifier.save('paper/classification_model.h5')\n",
    "\n",
    "tokenizer.save_pretrained('paper/tokenizer')\n",
    "\n",
    "with open(\"paper/scaler_stylometric.pkl\", \"wb\") as f:\n",
    "    pickle.dump(scaler, f)\n",
    "\n",
    "print(\"Model and configuration successfully saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b96d55d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext watermark\n",
    "%watermark\n",
    "%watermark -iv --gpu"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
